
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Modeling and generating sequences of polyphonic music with the RNN-RBM &#8212; DeepLearning 0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinxdoc.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Miscellaneous" href="utilities.html" />
    <link rel="prev" title="LSTM Networks for Sentiment Analysis" href="lstm.html" />
 
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-168290-9']);
  _gaq.push(['_trackPageview']);
</script>

  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="utilities.html" title="Miscellaneous"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="lstm.html" title="LSTM Networks for Sentiment Analysis"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="contents.html">DeepLearning 0.1 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Modeling and generating sequences of polyphonic music with the RNN-RBM</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="modeling-and-generating-sequences-of-polyphonic-music-with-the-rnn-rbm">
<span id="rnnrbm"></span><h1>Modeling and generating sequences of polyphonic music with the RNN-RBM<a class="headerlink" href="#modeling-and-generating-sequences-of-polyphonic-music-with-the-rnn-rbm" title="Permalink to this heading">¶</a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This tutorial demonstrates a basic implementation of the RNN-RBM as described in <a class="reference internal" href="references.html#boulangerlewandowski12" id="id1"><span>[BoulangerLewandowski12]</span></a>
(<a class="reference external" href="http://www-etud.iro.umontreal.ca/~boulanni/ICML2012.pdf">pdf</a>).
We assume the reader is familiar with
<a class="reference external" href="http://deeplearning.net/software/theano/library/scan.html">recurrent neural networks using the scan op</a>
and <a class="reference external" href="rbm.html">restricted Boltzmann machines (RBM)</a>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The code for this section is available for download here: <a class="reference external" href="code/rnnrbm.py">rnnrbm.py</a>.</p>
<p>You will need the modified <a class="reference external" href="http://www.iro.umontreal.ca/~lisa/deep/midi.zip">Python MIDI package (GPL license)</a> in your <code class="docutils literal notranslate"><span class="pre">$PYTHONPATH</span></code> or in the working directory in order to convert MIDI files to and from piano-rolls.
The script also assumes that the content of the <a class="reference external" href="http://www.iro.umontreal.ca/~lisa/deep/data/Nottingham.zip">Nottingham Database of folk tunes</a> has been extracted in the <code class="docutils literal notranslate"><span class="pre">../data</span></code> directory.
Alternative MIDI datasets are available <a class="reference external" href="http://www-etud.iro.umontreal.ca/~boulanni/icml2012">here</a>.</p>
<p>Note that both dependencies above can be setup automatically by running the <a class="reference external" href="https://github.com/lisa-lab/DeepLearningTutorials/blob/master/data/download.sh">download.sh</a> script in the <code class="docutils literal notranslate"><span class="pre">../data</span></code> directory of the <a class="reference external" href="https://github.com/lisa-lab/DeepLearningTutorials">Deep Learning Tutorials repository</a>.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>Need Theano 0.6 or more recent.</p>
</div>
<section id="the-rnn-rbm">
<h2>The RNN-RBM<a class="headerlink" href="#the-rnn-rbm" title="Permalink to this heading">¶</a></h2>
<p>The RNN-RBM is an energy-based model for density estimation of temporal sequences, where the feature vector <span class="math notranslate nohighlight">\(v^{(t)}\)</span> at time step <span class="math notranslate nohighlight">\(t\)</span> may be high-dimensional.
It allows to describe multimodal conditional distributions of <span class="math notranslate nohighlight">\(v^{(t)}|\mathcal A^{(t)}\)</span>, where <span class="math notranslate nohighlight">\(\mathcal A^{(t)}\equiv \{v_\tau|\tau&lt;t\}\)</span> denotes the <em>sequence history</em> at time <span class="math notranslate nohighlight">\(t\)</span>, via a series of conditional RBMs (one a each time step) whose parameters <span class="math notranslate nohighlight">\(b_v^{(t)},b_h^{(t)}\)</span> depend on the output of a deterministic RNN with hidden units <span class="math notranslate nohighlight">\(u^{(t)}\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-bv-t">
<span class="eqno">(1)<a class="headerlink" href="#equation-bv-t" title="Permalink to this equation">¶</a></span>\[b_v^{(t)} = b_v + W_{uv} u^{(t-1)}\]</div>
<div class="math notranslate nohighlight" id="equation-bh-t">
<span class="eqno">(2)<a class="headerlink" href="#equation-bh-t" title="Permalink to this equation">¶</a></span>\[b_h^{(t)} = b_h + W_{uh} u^{(t-1)}\]</div>
<p>and the single-layer RNN recurrence relation is defined by:</p>
<div class="math notranslate nohighlight" id="equation-u-t">
<span class="eqno">(3)<a class="headerlink" href="#equation-u-t" title="Permalink to this equation">¶</a></span>\[u^{(t)} = \tanh (b_u + W_{uu} u^{(t-1)} + W_{vu} v^{(t)})\]</div>
<p>The resulting model is unrolled in time in the following figure:</p>
<img alt="_images/rnnrbm.png" class="align-center" src="_images/rnnrbm.png" />
<p>The overall probability distribution is given by the sum over the <span class="math notranslate nohighlight">\(T\)</span> time steps in a given sequence:</p>
<div class="math notranslate nohighlight" id="equation-prob-rnnrbm">
<span class="eqno">(4)<a class="headerlink" href="#equation-prob-rnnrbm" title="Permalink to this equation">¶</a></span>\[P(\{v^{(t)}\}) = \sum_{t=1}^T P(v^{(t)} | \mathcal A^{(t)})\]</div>
<p>where the right-hand side multiplicand is the marginalized probability of the <span class="math notranslate nohighlight">\(t^\mathrm{th}\)</span> RBM.</p>
<p>Note that for clarity of the implementation, contrarily to <a class="reference internal" href="references.html#boulangerlewandowski12" id="id2"><span>[BoulangerLewandowski12]</span></a>, we use the obvious naming convention for weight matrices and we use <span class="math notranslate nohighlight">\(u^{(t)}\)</span> instead of <span class="math notranslate nohighlight">\(\hat h^{(t)}\)</span> for the recurrent hidden units.</p>
</section>
<section id="implementation">
<h2>Implementation<a class="headerlink" href="#implementation" title="Permalink to this heading">¶</a></h2>
<p>We wish to construct two Theano functions: one to train the RNN-RBM, and one to generate sample sequences from it.</p>
<p>For <em>training</em>, i.e. given <span class="math notranslate nohighlight">\(\{v^{(t)}\}\)</span>, the RNN hidden state <span class="math notranslate nohighlight">\(\{u^{(t)}\}\)</span> and the associated <span class="math notranslate nohighlight">\(\{b_v^{(t)}, b_h^{(t)}\}\)</span> parameters are deterministic and can be readily computed for each training sequence.
A stochastic gradient descent (SGD) update on the parameters can then be estimated via contrastive divergence (CD) on the individual time steps of a sequence in the same way that individual training examples are treated in a mini-batch for regular RBMs.</p>
<p><em>Sequence generation</em> is similar except that the <span class="math notranslate nohighlight">\(v^{(t)}\)</span> must be sampled sequentially at each time step with a separate (non-batch) Gibbs chain before being passed down to the recurrence and the sequence history.</p>
<section id="the-rbm-layer">
<h3>The RBM layer<a class="headerlink" href="#the-rbm-layer" title="Permalink to this heading">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">build_rbm</span></code> function shown below builds a Gibbs chain from an input mini-batch (a binary matrix) via the CD approximation.
Note that it also supports a single frame (a binary vector) in the non-batch case.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">build_rbm</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">bv</span><span class="p">,</span> <span class="n">bh</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;Construct a k-step Gibbs chain starting at v for an RBM.</span>

<span class="sd">    v : Theano vector or matrix</span>
<span class="sd">        If a matrix, multiple chains will be run in parallel (batch).</span>
<span class="sd">    W : Theano matrix</span>
<span class="sd">        Weight matrix of the RBM.</span>
<span class="sd">    bv : Theano vector</span>
<span class="sd">        Visible bias vector of the RBM.</span>
<span class="sd">    bh : Theano vector</span>
<span class="sd">        Hidden bias vector of the RBM.</span>
<span class="sd">    k : scalar or Theano scalar</span>
<span class="sd">        Length of the Gibbs chain.</span>

<span class="sd">    Return a (v_sample, cost, monitor, updates) tuple:</span>

<span class="sd">    v_sample : Theano vector or matrix with the same shape as `v`</span>
<span class="sd">        Corresponds to the generated sample(s).</span>
<span class="sd">    cost : Theano scalar</span>
<span class="sd">        Expression whose gradient with respect to W, bv, bh is the CD-k</span>
<span class="sd">        approximation to the log-likelihood of `v` (training example) under the</span>
<span class="sd">        RBM. The cost is averaged in the batch case.</span>
<span class="sd">    monitor: Theano scalar</span>
<span class="sd">        Pseudo log-likelihood (also averaged in the batch case).</span>
<span class="sd">    updates: dictionary of Theano variable -&gt; Theano variable</span>
<span class="sd">        The `updates` object returned by scan.&#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">gibbs_step</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
        <span class="n">mean_h</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">bh</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">mean_h</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">mean_h</span><span class="p">,</span>
                         <span class="n">dtype</span><span class="o">=</span><span class="n">theano</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">floatX</span><span class="p">)</span>
        <span class="n">mean_v</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">nnet</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">W</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">bv</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">binomial</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">mean_v</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">mean_v</span><span class="p">,</span>
                         <span class="n">dtype</span><span class="o">=</span><span class="n">theano</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">floatX</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mean_v</span><span class="p">,</span> <span class="n">v</span>

    <span class="n">chain</span><span class="p">,</span> <span class="n">updates</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">gibbs_step</span><span class="p">(</span><span class="n">v</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span> <span class="n">outputs_info</span><span class="o">=</span><span class="p">[</span><span class="n">v</span><span class="p">],</span>
                                 <span class="n">n_steps</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">v_sample</span> <span class="o">=</span> <span class="n">chain</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">mean_v</span> <span class="o">=</span> <span class="n">gibbs_step</span><span class="p">(</span><span class="n">v_sample</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">monitor</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">xlogx</span><span class="o">.</span><span class="n">xlogy0</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">mean_v</span><span class="p">)</span> <span class="o">+</span> <span class="n">T</span><span class="o">.</span><span class="n">xlogx</span><span class="o">.</span><span class="n">xlogy0</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">v</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">mean_v</span><span class="p">)</span>
    <span class="n">monitor</span> <span class="o">=</span> <span class="n">monitor</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">free_energy</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
        <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="n">v</span> <span class="o">*</span> <span class="n">bv</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">T</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">T</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">bh</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="p">(</span><span class="n">free_energy</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">-</span> <span class="n">free_energy</span><span class="p">(</span><span class="n">v_sample</span><span class="p">))</span> <span class="o">/</span> <span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">v_sample</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">monitor</span><span class="p">,</span> <span class="n">updates</span>
</pre></div>
</div>
</section>
<section id="the-rnn-layer">
<h3>The RNN layer<a class="headerlink" href="#the-rnn-layer" title="Permalink to this heading">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">build_rnnrbm</span></code> function defines the RNN recurrence relation to obtain the RBM parameters; the recurrence function is flexible enough to serve both in the training scenario where <span class="math notranslate nohighlight">\(v^{(t)}\)</span> is given and the “batch” RBM is constructed at the end on the whole sequence at once, and in the generation scenario where <span class="math notranslate nohighlight">\(v^{(t)}\)</span> is sampled separately at each time step using the Gibbs chain defined above.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">build_rnnrbm</span><span class="p">(</span><span class="n">n_visible</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_hidden_recurrent</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;Construct a symbolic RNN-RBM and initialize parameters.</span>

<span class="sd">    n_visible : integer</span>
<span class="sd">        Number of visible units.</span>
<span class="sd">    n_hidden : integer</span>
<span class="sd">        Number of hidden units of the conditional RBMs.</span>
<span class="sd">    n_hidden_recurrent : integer</span>
<span class="sd">        Number of hidden units of the RNN.</span>

<span class="sd">    Return a (v, v_sample, cost, monitor, params, updates_train, v_t,</span>
<span class="sd">    updates_generate) tuple:</span>

<span class="sd">    v : Theano matrix</span>
<span class="sd">        Symbolic variable holding an input sequence (used during training)</span>
<span class="sd">    v_sample : Theano matrix</span>
<span class="sd">        Symbolic variable holding the negative particles for CD log-likelihood</span>
<span class="sd">        gradient estimation (used during training)</span>
<span class="sd">    cost : Theano scalar</span>
<span class="sd">        Expression whose gradient (considering v_sample constant) corresponds</span>
<span class="sd">        to the LL gradient of the RNN-RBM (used during training)</span>
<span class="sd">    monitor : Theano scalar</span>
<span class="sd">        Frame-level pseudo-likelihood (useful for monitoring during training)</span>
<span class="sd">    params : tuple of Theano shared variables</span>
<span class="sd">        The parameters of the model to be optimized during training.</span>
<span class="sd">    updates_train : dictionary of Theano variable -&gt; Theano variable</span>
<span class="sd">        Update object that should be passed to theano.function when compiling</span>
<span class="sd">        the training function.</span>
<span class="sd">    v_t : Theano matrix</span>
<span class="sd">        Symbolic variable holding a generated sequence (used during sampling)</span>
<span class="sd">    updates_generate : dictionary of Theano variable -&gt; Theano variable</span>
<span class="sd">        Update object that should be passed to theano.function when compiling</span>
<span class="sd">        the generation function.&#39;&#39;&#39;</span>

    <span class="n">W</span> <span class="o">=</span> <span class="n">shared_normal</span><span class="p">(</span><span class="n">n_visible</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
    <span class="n">bv</span> <span class="o">=</span> <span class="n">shared_zeros</span><span class="p">(</span><span class="n">n_visible</span><span class="p">)</span>
    <span class="n">bh</span> <span class="o">=</span> <span class="n">shared_zeros</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">)</span>
    <span class="n">Wuh</span> <span class="o">=</span> <span class="n">shared_normal</span><span class="p">(</span><span class="n">n_hidden_recurrent</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">)</span>
    <span class="n">Wuv</span> <span class="o">=</span> <span class="n">shared_normal</span><span class="p">(</span><span class="n">n_hidden_recurrent</span><span class="p">,</span> <span class="n">n_visible</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">)</span>
    <span class="n">Wvu</span> <span class="o">=</span> <span class="n">shared_normal</span><span class="p">(</span><span class="n">n_visible</span><span class="p">,</span> <span class="n">n_hidden_recurrent</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">)</span>
    <span class="n">Wuu</span> <span class="o">=</span> <span class="n">shared_normal</span><span class="p">(</span><span class="n">n_hidden_recurrent</span><span class="p">,</span> <span class="n">n_hidden_recurrent</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">)</span>
    <span class="n">bu</span> <span class="o">=</span> <span class="n">shared_zeros</span><span class="p">(</span><span class="n">n_hidden_recurrent</span><span class="p">)</span>

    <span class="n">params</span> <span class="o">=</span> <span class="n">W</span><span class="p">,</span> <span class="n">bv</span><span class="p">,</span> <span class="n">bh</span><span class="p">,</span> <span class="n">Wuh</span><span class="p">,</span> <span class="n">Wuv</span><span class="p">,</span> <span class="n">Wvu</span><span class="p">,</span> <span class="n">Wuu</span><span class="p">,</span> <span class="n">bu</span>  <span class="c1"># learned parameters as shared</span>
                                                <span class="c1"># variables</span>

    <span class="n">v</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">matrix</span><span class="p">()</span>  <span class="c1"># a training sequence</span>
    <span class="n">u0</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_hidden_recurrent</span><span class="p">,))</span>  <span class="c1"># initial value for the RNN hidden</span>
                                         <span class="c1"># units</span>

    <span class="c1"># If `v_t` is given, deterministic recurrence to compute the variable</span>
    <span class="c1"># biases bv_t, bh_t at each time step. If `v_t` is None, same recurrence</span>
    <span class="c1"># but with a separate Gibbs chain at each time step to sample (generate)</span>
    <span class="c1"># from the RNN-RBM. The resulting sample v_t is returned in order to be</span>
    <span class="c1"># passed down to the sequence history.</span>
    <span class="k">def</span> <span class="nf">recurrence</span><span class="p">(</span><span class="n">v_t</span><span class="p">,</span> <span class="n">u_tm1</span><span class="p">):</span>
        <span class="n">bv_t</span> <span class="o">=</span> <span class="n">bv</span> <span class="o">+</span> <span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u_tm1</span><span class="p">,</span> <span class="n">Wuv</span><span class="p">)</span>
        <span class="n">bh_t</span> <span class="o">=</span> <span class="n">bh</span> <span class="o">+</span> <span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u_tm1</span><span class="p">,</span> <span class="n">Wuh</span><span class="p">)</span>
        <span class="n">generate</span> <span class="o">=</span> <span class="n">v_t</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">generate</span><span class="p">:</span>
            <span class="n">v_t</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">updates</span> <span class="o">=</span> <span class="n">build_rbm</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_visible</span><span class="p">,)),</span> <span class="n">W</span><span class="p">,</span> <span class="n">bv_t</span><span class="p">,</span>
                                           <span class="n">bh_t</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
        <span class="n">u_t</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">bu</span> <span class="o">+</span> <span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">v_t</span><span class="p">,</span> <span class="n">Wvu</span><span class="p">)</span> <span class="o">+</span> <span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u_tm1</span><span class="p">,</span> <span class="n">Wuu</span><span class="p">))</span>
        <span class="k">return</span> <span class="p">([</span><span class="n">v_t</span><span class="p">,</span> <span class="n">u_t</span><span class="p">],</span> <span class="n">updates</span><span class="p">)</span> <span class="k">if</span> <span class="n">generate</span> <span class="k">else</span> <span class="p">[</span><span class="n">u_t</span><span class="p">,</span> <span class="n">bv_t</span><span class="p">,</span> <span class="n">bh_t</span><span class="p">]</span>

    <span class="c1"># For training, the deterministic recurrence is used to compute all the</span>
    <span class="c1"># {bv_t, bh_t, 1 &lt;= t &lt;= T} given v. Conditional RBMs can then be trained</span>
    <span class="c1"># in batches using those parameters.</span>
    <span class="p">(</span><span class="n">u_t</span><span class="p">,</span> <span class="n">bv_t</span><span class="p">,</span> <span class="n">bh_t</span><span class="p">),</span> <span class="n">updates_train</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">v_t</span><span class="p">,</span> <span class="n">u_tm1</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span><span class="p">:</span> <span class="n">recurrence</span><span class="p">(</span><span class="n">v_t</span><span class="p">,</span> <span class="n">u_tm1</span><span class="p">),</span>
        <span class="n">sequences</span><span class="o">=</span><span class="n">v</span><span class="p">,</span> <span class="n">outputs_info</span><span class="o">=</span><span class="p">[</span><span class="n">u0</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">non_sequences</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>
    <span class="n">v_sample</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">monitor</span><span class="p">,</span> <span class="n">updates_rbm</span> <span class="o">=</span> <span class="n">build_rbm</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">bv_t</span><span class="p">[:],</span> <span class="n">bh_t</span><span class="p">[:],</span>
                                                     <span class="n">k</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">updates_train</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">updates_rbm</span><span class="p">)</span>

    <span class="c1"># symbolic loop for sequence generation</span>
    <span class="p">(</span><span class="n">v_t</span><span class="p">,</span> <span class="n">u_t</span><span class="p">),</span> <span class="n">updates_generate</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">u_tm1</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span><span class="p">:</span> <span class="n">recurrence</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">u_tm1</span><span class="p">),</span>
        <span class="n">outputs_info</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">u0</span><span class="p">],</span> <span class="n">non_sequences</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">v_sample</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">monitor</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">updates_train</span><span class="p">,</span> <span class="n">v_t</span><span class="p">,</span>
            <span class="n">updates_generate</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="putting-it-all-together">
<h3>Putting it all together<a class="headerlink" href="#putting-it-all-together" title="Permalink to this heading">¶</a></h3>
<p>We now have all the necessary ingredients to start training our network on real symbolic sequences of polyphonic music.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">RnnRbm</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;Simple class to train an RNN-RBM from MIDI files and to generate sample</span>
<span class="sd">    sequences.&#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_hidden</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span>
        <span class="n">n_hidden_recurrent</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
        <span class="n">r</span><span class="o">=</span><span class="p">(</span><span class="mi">21</span><span class="p">,</span> <span class="mi">109</span><span class="p">),</span>
        <span class="n">dt</span><span class="o">=</span><span class="mf">0.3</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;Constructs and compiles Theano functions for training and sequence</span>
<span class="sd">        generation.</span>

<span class="sd">        n_hidden : integer</span>
<span class="sd">            Number of hidden units of the conditional RBMs.</span>
<span class="sd">        n_hidden_recurrent : integer</span>
<span class="sd">            Number of hidden units of the RNN.</span>
<span class="sd">        lr : float</span>
<span class="sd">            Learning rate</span>
<span class="sd">        r : (integer, integer) tuple</span>
<span class="sd">            Specifies the pitch range of the piano-roll in MIDI note numbers,</span>
<span class="sd">            including r[0] but not r[1], such that r[1]-r[0] is the number of</span>
<span class="sd">            visible units of the RBM at a given time step. The default (21,</span>
<span class="sd">            109) corresponds to the full range of piano (88 notes).</span>
<span class="sd">        dt : float</span>
<span class="sd">            Sampling period when converting the MIDI files into piano-rolls, or</span>
<span class="sd">            equivalently the time difference between consecutive time steps.&#39;&#39;&#39;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">r</span> <span class="o">=</span> <span class="n">r</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dt</span> <span class="o">=</span> <span class="n">dt</span>
        <span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">v_sample</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">monitor</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">updates_train</span><span class="p">,</span> <span class="n">v_t</span><span class="p">,</span>
            <span class="n">updates_generate</span><span class="p">)</span> <span class="o">=</span> <span class="n">build_rnnrbm</span><span class="p">(</span>
                <span class="n">r</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="n">n_hidden</span><span class="p">,</span>
                <span class="n">n_hidden_recurrent</span>
            <span class="p">)</span>

        <span class="n">gradient</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">consider_constant</span><span class="o">=</span><span class="p">[</span><span class="n">v_sample</span><span class="p">])</span>
        <span class="n">updates_train</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="n">p</span> <span class="o">-</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">g</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">g</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">gradient</span><span class="p">))</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_function</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
            <span class="p">[</span><span class="n">v</span><span class="p">],</span>
            <span class="n">monitor</span><span class="p">,</span>
            <span class="n">updates</span><span class="o">=</span><span class="n">updates_train</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generate_function</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
            <span class="p">[],</span>
            <span class="n">v_t</span><span class="p">,</span>
            <span class="n">updates</span><span class="o">=</span><span class="n">updates_generate</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">files</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">200</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;Train the RNN-RBM via stochastic gradient descent (SGD) using MIDI</span>
<span class="sd">        files converted to piano-rolls.</span>

<span class="sd">        files : list of strings</span>
<span class="sd">            List of MIDI files that will be loaded as piano-rolls for training.</span>
<span class="sd">        batch_size : integer</span>
<span class="sd">            Training sequences will be split into subsequences of at most this</span>
<span class="sd">            size before applying the SGD updates.</span>
<span class="sd">        num_epochs : integer</span>
<span class="sd">            Number of epochs (pass over the training set) performed. The user</span>
<span class="sd">            can safely interrupt training with Ctrl+C at any time.&#39;&#39;&#39;</span>

        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">files</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;Training set is empty!&#39;</span> \
                               <span class="s1">&#39; (did you download the data files?)&#39;</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="p">[</span><span class="n">midiread</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">r</span><span class="p">,</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">dt</span><span class="p">)</span><span class="o">.</span><span class="n">piano_roll</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">theano</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">floatX</span><span class="p">)</span>
                   <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">files</span><span class="p">]</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
                <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
                <span class="n">costs</span> <span class="o">=</span> <span class="p">[]</span>

                <span class="k">for</span> <span class="n">s</span><span class="p">,</span> <span class="n">sequence</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sequence</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">):</span>
                        <span class="n">cost</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">sequence</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">])</span>
                        <span class="n">costs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>

                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">%i</span><span class="s1">/</span><span class="si">%i</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">))</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">costs</span><span class="p">))</span>
                <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

        <span class="k">except</span> <span class="ne">KeyboardInterrupt</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Interrupted by user.&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">show</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&#39;&#39;&#39;Generate a sample sequence, plot the resulting piano-roll and save</span>
<span class="sd">        it as a MIDI file.</span>

<span class="sd">        filename : string</span>
<span class="sd">            A MIDI file will be created at this location.</span>
<span class="sd">        show : boolean</span>
<span class="sd">            If True, a piano-roll of the generated sequence will be shown.&#39;&#39;&#39;</span>

        <span class="n">piano_roll</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_function</span><span class="p">()</span>
        <span class="n">midiwrite</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">piano_roll</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">r</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">show</span><span class="p">:</span>
            <span class="n">extent</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">piano_roll</span><span class="p">))</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">r</span>
            <span class="n">pylab</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
            <span class="n">pylab</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">piano_roll</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">origin</span><span class="o">=</span><span class="s1">&#39;lower&#39;</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
                         <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">pylab</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">gray_r</span><span class="p">,</span>
                         <span class="n">extent</span><span class="o">=</span><span class="n">extent</span><span class="p">)</span>
            <span class="n">pylab</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;time (s)&#39;</span><span class="p">)</span>
            <span class="n">pylab</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;MIDI note number&#39;</span><span class="p">)</span>
            <span class="n">pylab</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;generated piano-roll&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="results">
<h2>Results<a class="headerlink" href="#results" title="Permalink to this heading">¶</a></h2>
<p>We ran the code on the Nottingham database for 200 epochs; training took approximately 24 hours.</p>
<p>The output was the following:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Epoch 1/200 -15.0308940028
Epoch 2/200 -10.4892606673
Epoch 3/200 -10.2394696138
Epoch 4/200 -10.1431669994
Epoch 5/200 -9.7005382843
Epoch 6/200 -8.5985647524
Epoch 7/200 -8.35115428534
Epoch 8/200 -8.26453580552
Epoch 9/200 -8.21208991542
Epoch 10/200 -8.16847274143

... truncated for brevity ...

Epoch 190/200 -4.74799179994
Epoch 191/200 -4.73488515216
Epoch 192/200 -4.7326138489
Epoch 193/200 -4.73841636884
Epoch 194/200 -4.70255511452
Epoch 195/200 -4.71872634914
Epoch 196/200 -4.7276415885
Epoch 197/200 -4.73497644728
Epoch 198/200 -inf
Epoch 199/200 -4.75554987143
Epoch 200/200 -4.72591935412
</pre></div>
</div>
<p>The figures below show the piano-rolls of two sample sequences and we provide the corresponding MIDI files:</p>
<figure class="align-default" id="id4">
<a class="reference internal image-reference" href="_images/sample1.png"><img alt="_images/sample1.png" src="_images/sample1.png" style="width: 487.2px; height: 367.2px;" /></a>
<figcaption>
<p><span class="caption-text">Listen to <a class="reference external" href="http://www-etud.iro.umontreal.ca/~boulanni/sample1.mid">sample1.mid</a></span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<figure class="align-default" id="id5">
<a class="reference internal image-reference" href="_images/sample2.png"><img alt="_images/sample2.png" src="_images/sample2.png" style="width: 487.2px; height: 367.2px;" /></a>
<figcaption>
<p><span class="caption-text">Listen to <a class="reference external" href="http://www-etud.iro.umontreal.ca/~boulanni/sample2.mid">sample2.mid</a></span><a class="headerlink" href="#id5" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</section>
<section id="how-to-improve-this-code">
<h2>How to improve this code<a class="headerlink" href="#how-to-improve-this-code" title="Permalink to this heading">¶</a></h2>
<p>The code shown in this tutorial is a stripped-down version that can be improved in the following ways:</p>
<ul class="simple">
<li><p>Preprocessing: transposing the sequences in a common tonality (e.g. C major / minor) and normalizing the tempo in beats (quarternotes) per minute can have the most effect on the generative quality of the model.</p></li>
<li><p>Pretraining techniques: initialize the <span class="math notranslate nohighlight">\(W,b_v,b_h\)</span> parameters with independent RBMs with fully shuffled frames (i.e. <span class="math notranslate nohighlight">\(W_{uh}=W_{uv}=W_{uu}=W_{vu}=0\)</span>); initialize the <span class="math notranslate nohighlight">\(W_{uv},W_{uu},W_{vu},b_u\)</span> parameters of the RNN with the auxiliary cross-entropy objective via either SGD or, preferably, Hessian-free optimization <a class="reference internal" href="references.html#boulangerlewandowski12" id="id3"><span>[BoulangerLewandowski12]</span></a>.</p></li>
<li><p>Optimization techniques: gradient clipping, Nesterov momentum and the use of NADE for conditional density estimation.</p></li>
<li><p>Hyperparameter search: learning rate (separately for the RBM and RNN parts), learning rate schedules, batch size, number of hidden units (recurrent and RBM), momentum coefficient, momentum schedule, Gibbs chain length <span class="math notranslate nohighlight">\(k\)</span> and early stopping.</p></li>
<li><p>Learn the initial condition <span class="math notranslate nohighlight">\(u^{(0)}\)</span> as a model parameter.</p></li>
</ul>
<p>A few samples generated with code including these features are available here: <a class="reference external" href="http://www-etud.iro.umontreal.ca/~boulanni/sequences.zip">sequences.zip</a>.</p>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <div>
    <h3><a href="contents.html">Table of Contents</a></h3>
    <ul>
<li><a class="reference internal" href="#">Modeling and generating sequences of polyphonic music with the RNN-RBM</a><ul>
<li><a class="reference internal" href="#the-rnn-rbm">The RNN-RBM</a></li>
<li><a class="reference internal" href="#implementation">Implementation</a><ul>
<li><a class="reference internal" href="#the-rbm-layer">The RBM layer</a></li>
<li><a class="reference internal" href="#the-rnn-layer">The RNN layer</a></li>
<li><a class="reference internal" href="#putting-it-all-together">Putting it all together</a></li>
</ul>
</li>
<li><a class="reference internal" href="#results">Results</a></li>
<li><a class="reference internal" href="#how-to-improve-this-code">How to improve this code</a></li>
</ul>
</li>
</ul>

  </div>
  <div>
    <h4>Previous topic</h4>
    <p class="topless"><a href="lstm.html"
                          title="previous chapter">LSTM Networks for Sentiment Analysis</a></p>
  </div>
  <div>
    <h4>Next topic</h4>
    <p class="topless"><a href="utilities.html"
                          title="next chapter">Miscellaneous</a></p>
  </div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/rnnrbm.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="utilities.html" title="Miscellaneous"
             >next</a> |</li>
        <li class="right" >
          <a href="lstm.html" title="LSTM Networks for Sentiment Analysis"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="contents.html">DeepLearning 0.1 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Modeling and generating sequences of polyphonic music with the RNN-RBM</a></li> 
      </ul>
    </div>

    <div class="footer" role="contentinfo">
        &#169; Copyright 2008--2010, LISA lab.
      Last updated on May 11, 2023.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 6.1.3.
    </div>
<script type="text/javascript">
  (function() {
    var ga = document.createElement('script');
    ga.src = ('https:' == document.location.protocol ?
              'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    ga.setAttribute('async', 'true');
    document.documentElement.firstChild.appendChild(ga);
  })();
</script>

  </body>
</html>