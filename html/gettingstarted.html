
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Getting Started &#8212; DeepLearning 0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinxdoc.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Classifying MNIST digits using Logistic Regression" href="logreg.html" />
    <link rel="prev" title="Deep Learning Tutorials" href="index.html" />
 
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-168290-9']);
  _gaq.push(['_trackPageview']);
</script>

  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="logreg.html" title="Classifying MNIST digits using Logistic Regression"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="index.html" title="Deep Learning Tutorials"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="contents.html">DeepLearning 0.1 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Getting Started</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="getting-started">
<span id="gettingstarted"></span><h1>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this heading">¶</a></h1>
<p>These tutorials do not attempt to make up for a graduate or undergraduate course
in machine learning, but we do make a rapid overview of some important concepts
(and notation) to make sure that we’re on the same page.  You’ll also need to
download the datasets mentioned in this chapter in order to run the example code of
the up-coming tutorials.</p>
<span class="target" id="download"></span><section id="index-0">
<span id="id1"></span><h2>Download<a class="headerlink" href="#index-0" title="Permalink to this heading">¶</a></h2>
<p>On each learning algorithm page, you will be able to download the corresponding files. If you want to download all of them at the same time, you can clone the git repository of the tutorial:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">lisa</span><span class="o">-</span><span class="n">lab</span><span class="o">/</span><span class="n">DeepLearningTutorials</span><span class="o">.</span><span class="n">git</span>
</pre></div>
</div>
<p>On Linux or Mac systems, after cloning, all datasets can be downloaded at once with:</p>
<blockquote>
<div><p>cd DeepLearningTutorials/data
./download.sh</p>
</div></blockquote>
<span class="target" id="datasets"></span></section>
<section id="index-1">
<span id="id2"></span><h2>Datasets<a class="headerlink" href="#index-1" title="Permalink to this heading">¶</a></h2>
<section id="mnist-dataset">
<span id="index-2"></span><h3>MNIST Dataset<a class="headerlink" href="#mnist-dataset" title="Permalink to this heading">¶</a></h3>
<p>(<a class="reference external" href="http://deeplearning.net/data/mnist/mnist.pkl.gz">mnist.pkl.gz</a>)</p>
<blockquote>
<div><p>The <a class="reference external" href="http://yann.lecun.com/exdb/mnist">MNIST</a> dataset consists of handwritten
digit images and it is divided in 60,000 examples for the training set and
10,000 examples for testing. In many papers as well as in this tutorial, the
official training set of 60,000 is divided into an actual training set of 50,000
examples and 10,000 validation examples (for selecting hyper-parameters like
learning rate and size of the model). All digit images have been size-normalized and
centered in a fixed size image of 28 x 28 pixels. In the original dataset
each pixel of the image is represented by a value between 0 and 255, where
0 is black, 255 is  white and anything in between is a different shade of grey.</p>
<p>Here are some examples of MNIST digits:</p>
<blockquote>
<div><p><img alt="0" src="_images/mnist_0.png" /> <img alt="1" src="_images/mnist_1.png" /> <img alt="2" src="_images/mnist_2.png" /> <img alt="3" src="_images/mnist_3.png" /> <img alt="4" src="_images/mnist_4.png" /> <img alt="5" src="_images/mnist_5.png" /></p>
</div></blockquote>
<p>For convenience we pickled the dataset to make it easier to use in python.
It is available for download <a class="reference external" href="http://deeplearning.net/data/mnist/mnist.pkl.gz">here</a>.
The pickled file represents a tuple of 3 lists : the training set, the
validation set and the testing set. Each of the three lists is a pair
formed from a list of images and a list of class labels for each of the
images. An image is represented as numpy 1-dimensional array of 784 (28
x 28) float values between 0 and 1 (0 stands for black, 1 for white).
The labels are numbers between 0 and 9 indicating which digit the image
represents. The code block below shows how to load the dataset.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">cPickle</span><span class="o">,</span> <span class="nn">gzip</span><span class="o">,</span> <span class="nn">numpy</span>

<span class="c1"># Load the dataset</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;mnist.pkl.gz&#39;</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span>
<span class="n">train_set</span><span class="p">,</span> <span class="n">valid_set</span><span class="p">,</span> <span class="n">test_set</span> <span class="o">=</span> <span class="n">cPickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>When using the dataset, we usually divide it in minibatches (see
<a class="reference internal" href="#opt-sgd"><span class="std std-ref">Stochastic Gradient Descent</span></a>). We encourage you to store the dataset into shared
variables and access it based on the minibatch index, given a fixed
and known batch size. The reason behind shared variables is
related to using the GPU. There is a large overhead when copying data
into the GPU memory. If you would copy data on request (each minibatch
individually when needed) as the code will do if you do not use shared
variables, due to this overhead, the GPU code will not be much faster
then the CPU code (maybe even slower). If you have your data in
Theano shared variables though, you give Theano the possibility to copy
the entire data on the GPU in a single call when the shared variables are constructed.
Afterwards the GPU can access any minibatch by taking a slice from this
shared variables, without needing to copy any information from the CPU
memory and therefore bypassing the overhead.
Because the datapoints and their labels are usually of different nature
(labels are usually integers while datapoints are real numbers) we
suggest to use different variables for label and data. Also we recommend
using different variables for the training set, validation set and
testing set to make the code more readable (resulting in 6 different
shared variables).</p>
<p>Since now the data is in one variable, and a minibatch is defined as a
slice of that variable, it comes more natural to define a minibatch by
indicating its index and its size. In our setup the batch size stays constant
throughout the execution of the code, therefore a function will actually
require only the index to identify on which datapoints to work.
The code below shows how to store your data and how to
access a minibatch:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">shared_dataset</span><span class="p">(</span><span class="n">data_xy</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Function that loads the dataset into shared variables</span>

<span class="sd">    The reason we store our dataset in shared variables is to allow</span>
<span class="sd">    Theano to copy it into the GPU memory (when code is run on GPU).</span>
<span class="sd">    Since copying data into the GPU is slow, copying a minibatch everytime</span>
<span class="sd">    is needed (the default behaviour if the data is not in a shared</span>
<span class="sd">    variable) would lead to a large decrease in performance.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">data_x</span><span class="p">,</span> <span class="n">data_y</span> <span class="o">=</span> <span class="n">data_xy</span>
    <span class="n">shared_x</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">data_x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">theano</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">floatX</span><span class="p">))</span>
    <span class="n">shared_y</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">data_y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">theano</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">floatX</span><span class="p">))</span>
    <span class="c1"># When storing data on the GPU it has to be stored as floats</span>
    <span class="c1"># therefore we will store the labels as ``floatX`` as well</span>
    <span class="c1"># (``shared_y`` does exactly that). But during our computations</span>
    <span class="c1"># we need them as ints (we use labels as index, and if they are</span>
    <span class="c1"># floats it doesn&#39;t make sense) therefore instead of returning</span>
    <span class="c1"># ``shared_y`` we will have to cast it to int. This little hack</span>
    <span class="c1"># lets us get around this issue</span>
    <span class="k">return</span> <span class="n">shared_x</span><span class="p">,</span> <span class="n">T</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">shared_y</span><span class="p">,</span> <span class="s1">&#39;int32&#39;</span><span class="p">)</span>

<span class="n">test_set_x</span><span class="p">,</span> <span class="n">test_set_y</span> <span class="o">=</span> <span class="n">shared_dataset</span><span class="p">(</span><span class="n">test_set</span><span class="p">)</span>
<span class="n">valid_set_x</span><span class="p">,</span> <span class="n">valid_set_y</span> <span class="o">=</span> <span class="n">shared_dataset</span><span class="p">(</span><span class="n">valid_set</span><span class="p">)</span>
<span class="n">train_set_x</span><span class="p">,</span> <span class="n">train_set_y</span> <span class="o">=</span> <span class="n">shared_dataset</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">500</span>    <span class="c1"># size of the minibatch</span>

<span class="c1"># accessing the third minibatch of the training set</span>

<span class="n">data</span>  <span class="o">=</span> <span class="n">train_set_x</span><span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">:</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">]</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">train_set_y</span><span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">:</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">]</span>
</pre></div>
</div>
</div></blockquote>
<p>The data has to be stored as floats on the GPU ( the right
<code class="docutils literal notranslate"><span class="pre">dtype</span></code> for storing on the GPU is given by <code class="docutils literal notranslate"><span class="pre">theano.config.floatX</span></code>).
To get around this shortcoming for the labels, we store them as float,
and then cast it to int.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you are running your code on the GPU and the dataset you are using
is too large to fit in memory the code will crash. In such a case you
should store the data in a shared variable. You can however store a
sufficiently small chunk of your data (several minibatches) in a shared
variable and use that during training. Once you got through the chunk,
update the values it stores. This way you minimize the number of data
transfers between CPU memory and GPU memory.</p>
</div>
</section>
</section>
<section id="notation">
<span id="index-3"></span><h2>Notation<a class="headerlink" href="#notation" title="Permalink to this heading">¶</a></h2>
<section id="dataset-notation">
<span id="index-4"></span><h3>Dataset notation<a class="headerlink" href="#dataset-notation" title="Permalink to this heading">¶</a></h3>
<p>We label data sets as <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>. When the distinction is important, we
indicate train, validation, and test sets as: <span class="math notranslate nohighlight">\(\mathcal{D}_{train}\)</span>,
<span class="math notranslate nohighlight">\(\mathcal{D}_{valid}\)</span> and <span class="math notranslate nohighlight">\(\mathcal{D}_{test}\)</span>. The validation set
is used to perform model selection and hyper-parameter selection, whereas
the test set is used to evaluate the final generalization error and
compare different algorithms in an unbiased way.</p>
<p>The tutorials mostly deal with classification problems, where each data set
<span class="math notranslate nohighlight">\(\mathcal{D}\)</span> is an indexed set of pairs <span class="math notranslate nohighlight">\((x^{(i)},y^{(i)})\)</span>. We
use superscripts to distinguish training set examples: <span class="math notranslate nohighlight">\(x^{(i)} \in
\mathcal{R}^D\)</span> is thus the i-th training example of dimensionality <span class="math notranslate nohighlight">\(D\)</span>. Similarly,
<span class="math notranslate nohighlight">\(y^{(i)} \in \{0, ..., L\}\)</span> is the i-th label assigned to input
<span class="math notranslate nohighlight">\(x^{(i)}\)</span>. It is straightforward to extend these examples to
ones where <span class="math notranslate nohighlight">\(y^{(i)}\)</span> has other types (e.g. Gaussian for regression,
or groups of multinomials for predicting multiple symbols).</p>
</section>
<section id="math-conventions">
<span id="index-5"></span><h3>Math Conventions<a class="headerlink" href="#math-conventions" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(W\)</span>: upper-case symbols refer to a matrix unless specified otherwise</p></li>
<li><p><span class="math notranslate nohighlight">\(W_{ij}\)</span>: element at i-th row and j-th column of matrix <span class="math notranslate nohighlight">\(W\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(W_{i \cdot}, W_i\)</span>: vector, i-th row of matrix <span class="math notranslate nohighlight">\(W\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(W_{\cdot j}\)</span>: vector, j-th column of matrix <span class="math notranslate nohighlight">\(W\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(b\)</span>: lower-case symbols refer to a vector unless specified otherwise</p></li>
<li><p><span class="math notranslate nohighlight">\(b_i\)</span>: i-th element of vector <span class="math notranslate nohighlight">\(b\)</span></p></li>
</ul>
</section>
<section id="list-of-symbols-and-acronyms">
<span id="index-6"></span><h3>List of Symbols and acronyms<a class="headerlink" href="#list-of-symbols-and-acronyms" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(D\)</span>: number of input dimensions.</p></li>
<li><p><span class="math notranslate nohighlight">\(D_h^{(i)}\)</span>: number of hidden units in the <span class="math notranslate nohighlight">\(i\)</span>-th layer.</p></li>
<li><p><span class="math notranslate nohighlight">\(f_{\theta}(x)\)</span>, <span class="math notranslate nohighlight">\(f(x)\)</span>: classification function associated with a model <span class="math notranslate nohighlight">\(P(Y|x,\theta)\)</span>, defined as <span class="math notranslate nohighlight">\({\rm argmax}_k P(Y=k|x,\theta)\)</span>.
Note that we will often drop the <span class="math notranslate nohighlight">\(\theta\)</span> subscript.</p></li>
<li><p>L: number of labels.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathcal{L}(\theta, \cal{D})\)</span>: log-likelihood <span class="math notranslate nohighlight">\(\cal{D}\)</span>
of the model defined by parameters <span class="math notranslate nohighlight">\(\theta\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\ell(\theta, \cal{D})\)</span> empirical loss of the prediction function f
parameterized by <span class="math notranslate nohighlight">\(\theta\)</span> on data set <span class="math notranslate nohighlight">\(\cal{D}\)</span>.</p></li>
<li><p>NLL: negative log-likelihood</p></li>
<li><p><span class="math notranslate nohighlight">\(\theta\)</span>: set of all parameters for a given model</p></li>
</ul>
</section>
<section id="python-namespaces">
<span id="index-7"></span><h3>Python Namespaces<a class="headerlink" href="#python-namespaces" title="Permalink to this heading">¶</a></h3>
<p>Tutorial code often uses the following namespaces:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">theano</span>
<span class="kn">import</span> <span class="nn">theano.tensor</span> <span class="k">as</span> <span class="nn">T</span>
<span class="kn">import</span> <span class="nn">numpy</span>
</pre></div>
</div>
</section>
</section>
<section id="a-primer-on-supervised-optimization-for-deep-learning">
<h2>A Primer on Supervised Optimization for Deep Learning<a class="headerlink" href="#a-primer-on-supervised-optimization-for-deep-learning" title="Permalink to this heading">¶</a></h2>
<p id="stoch-grad-label">What’s exciting about Deep Learning is largely the use of unsupervised learning
of deep networks.  But supervised learning also plays an important role.  The
utility of unsupervised <em>pre-training</em> is often evaluated on the basis of what
performance can be achieved after supervised <em>fine-tuning</em>.  This chapter
reviews the basics of supervised learning for classification models, and covers
the minibatch stochastic gradient descent algorithm that is used to fine-tune
many of the models in the Deep Learning Tutorials. Have a look at these
<a class="reference external" href="http://www.iro.umontreal.ca/~pift6266/H10/notes/gradient.html">introductory course notes on gradient-based learning</a>
for more basics on the notion of optimizing a training criterion using the gradient.</p>
<section id="learning-a-classifier">
<span id="opt-learn-classifier"></span><h3>Learning a Classifier<a class="headerlink" href="#learning-a-classifier" title="Permalink to this heading">¶</a></h3>
<section id="zero-one-loss">
<span id="index-8"></span><h4>Zero-One Loss<a class="headerlink" href="#zero-one-loss" title="Permalink to this heading">¶</a></h4>
<p>The models presented in these deep learning tutorials are mostly used
for classification. The objective in training a classifier is to minimize the number
of errors (zero-one loss) on unseen examples. If <span class="math notranslate nohighlight">\(f: R^D \rightarrow
\{0,...,L\}\)</span> is the prediction function, then this loss can be written as:</p>
<div class="math notranslate nohighlight">
\[\ell_{0,1} = \sum_{i=0}^{|\mathcal{D}|} I_{f(x^{(i)}) \neq y^{(i)}}\]</div>
<p>where either <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> is the training
set (during training)
or <span class="math notranslate nohighlight">\(\mathcal{D} \cap \mathcal{D}_{train} = \emptyset\)</span>
(to avoid biasing the evaluation of validation or test error). <span class="math notranslate nohighlight">\(I\)</span> is the
indicator function defined as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}I_x = \left\{\begin{array}{ccc}
      1&amp;\mbox{ if $x$ is True} \\
      0&amp;\mbox{ otherwise}\end{array}\right.\end{split}\]</div>
<p>In this tutorial, <span class="math notranslate nohighlight">\(f\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[f(x) = {\rm argmax}_k P(Y=k | x, \theta)\]</div>
<p>In python, using Theano this can be written as:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># zero_one_loss is a Theano variable representing a symbolic</span>
<span class="c1"># expression of the zero one loss ; to get the actual value this</span>
<span class="c1"># symbolic expression has to be compiled into a Theano function (see</span>
<span class="c1"># the Theano tutorial for more details)</span>
<span class="n">zero_one_loss</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">neq</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">p_y_given_x</span><span class="p">),</span> <span class="n">y</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="negative-log-likelihood-loss">
<span id="index-9"></span><h4>Negative Log-Likelihood Loss<a class="headerlink" href="#negative-log-likelihood-loss" title="Permalink to this heading">¶</a></h4>
<p>Since the zero-one loss is not differentiable, optimizing it for large models
(thousands or millions of parameters) is prohibitively expensive
(computationally). We thus maximize the log-likelihood of our classifier given
all the labels in a training set.</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(\theta, \mathcal{D}) =
    \sum_{i=0}^{|\mathcal{D}|} \log P(Y=y^{(i)} | x^{(i)}, \theta)\]</div>
<p>The likelihood of the correct class is not the same as the
number of right predictions, but from the point of view of a randomly
initialized classifier they are pretty similar.
Remember that likelihood and zero-one loss are different objectives;
you should see that they are correlated on the validation set but
sometimes one will rise while the other falls, or vice-versa.</p>
<p>Since we usually speak in terms of minimizing a loss function, learning will
thus attempt to <strong>minimize</strong> the <strong>negative</strong> log-likelihood (NLL), defined
as:</p>
<div class="math notranslate nohighlight">
\[NLL(\theta, \mathcal{D}) = - \sum_{i=0}^{|\mathcal{D}|} \log P(Y=y^{(i)} | x^{(i)}, \theta)\]</div>
<p>The NLL of our classifier is a differentiable surrogate for the zero-one loss,
and we use the gradient of this function over our training data as a
supervised learning signal for deep learning of a classifier.</p>
<p>This can be computed using the following line of code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># NLL is a symbolic variable ; to get the actual value of NLL, this symbolic</span>
<span class="c1"># expression has to be compiled into a Theano function (see the Theano</span>
<span class="c1"># tutorial for more details)</span>
<span class="n">NLL</span> <span class="o">=</span> <span class="o">-</span><span class="n">T</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">T</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p_y_given_x</span><span class="p">)[</span><span class="n">T</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">y</span><span class="p">])</span>
<span class="c1"># note on syntax: T.arange(y.shape[0]) is a vector of integers [0,1,2,...,len(y)].</span>
<span class="c1"># Indexing a matrix M by the two vectors [0,1,...,K], [a,b,...,k] returns the</span>
<span class="c1"># elements M[0,a], M[1,b], ..., M[K,k] as a vector.  Here, we use this</span>
<span class="c1"># syntax to retrieve the log-probability of the correct labels, y.</span>
</pre></div>
</div>
</section>
</section>
<section id="stochastic-gradient-descent">
<span id="opt-sgd"></span><span id="index-10"></span><h3>Stochastic Gradient Descent<a class="headerlink" href="#stochastic-gradient-descent" title="Permalink to this heading">¶</a></h3>
<p>What is ordinary gradient descent?  it is a simple
algorithm in which we repeatedly make small steps downward on an error
surface defined by a loss function of some parameters.
For the purpose of ordinary gradient descent we consider that the training
data is rolled into the loss function. Then the pseudocode of this
algorithm can be described as:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># GRADIENT DESCENT</span>

<span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    <span class="n">d_loss_wrt_params</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># compute gradient</span>
    <span class="n">params</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">d_loss_wrt_params</span>
    <span class="k">if</span> <span class="o">&lt;</span><span class="n">stopping</span> <span class="n">condition</span> <span class="ow">is</span> <span class="n">met</span><span class="o">&gt;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">params</span>
</pre></div>
</div>
<p>Stochastic gradient descent (SGD) works according to the same principles as
ordinary gradient descent, but proceeds more quickly by estimating the gradient from just
a few examples at a time instead of the entire training set.  In its purest
form, we estimate the gradient from just a single example at a time.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># STOCHASTIC GRADIENT DESCENT</span>
<span class="k">for</span> <span class="p">(</span><span class="n">x_i</span><span class="p">,</span><span class="n">y_i</span><span class="p">)</span> <span class="ow">in</span> <span class="n">training_set</span><span class="p">:</span>
                            <span class="c1"># imagine an infinite generator</span>
                            <span class="c1"># that may repeat examples (if there is only a finite training set)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x_i</span><span class="p">,</span> <span class="n">y_i</span><span class="p">)</span>
    <span class="n">d_loss_wrt_params</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># compute gradient</span>
    <span class="n">params</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">d_loss_wrt_params</span>
    <span class="k">if</span> <span class="o">&lt;</span><span class="n">stopping</span> <span class="n">condition</span> <span class="ow">is</span> <span class="n">met</span><span class="o">&gt;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">params</span>
</pre></div>
</div>
<p>The variant that we recommend for deep learning is a further twist on
stochastic gradient descent using so-called “minibatches”.
Minibatch SGD (MSGD) works identically to SGD, except that we use more than
one training example to make each estimate of the gradient.  This technique reduces
variance in the estimate of the gradient, and often makes better use of the
hierarchical memory organization in modern computers.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="p">(</span><span class="n">x_batch</span><span class="p">,</span><span class="n">y_batch</span><span class="p">)</span> <span class="ow">in</span> <span class="n">train_batches</span><span class="p">:</span>
                            <span class="c1"># imagine an infinite generator</span>
                            <span class="c1"># that may repeat examples</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
    <span class="n">d_loss_wrt_params</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># compute gradient using theano</span>
    <span class="n">params</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">d_loss_wrt_params</span>
    <span class="k">if</span> <span class="o">&lt;</span><span class="n">stopping</span> <span class="n">condition</span> <span class="ow">is</span> <span class="n">met</span><span class="o">&gt;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">params</span>
</pre></div>
</div>
<p>There is a tradeoff in the choice of the minibatch size <span class="math notranslate nohighlight">\(B\)</span>.  The
reduction of variance and use of SIMD instructions helps most when increasing
<span class="math notranslate nohighlight">\(B\)</span> from 1 to 2, but the marginal improvement fades rapidly to nothing.
With large <span class="math notranslate nohighlight">\(B\)</span>, time is wasted in reducing the variance of the gradient
estimator, that time would be better spent on additional gradient steps.
An optimal <span class="math notranslate nohighlight">\(B\)</span> is model-, dataset-, and hardware-dependent, and can be
anywhere from 1 to maybe several hundreds.  In the tutorial we set it to 20,
but this choice is almost arbitrary (though harmless).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you are training for a fixed number of epochs, the minibatch size becomes important
because it controls the number of updates done to your parameters. Training the same model
for 10 epochs using a batch size of 1 yields completely different results compared
to training for the same 10 epochs but with a batchsize of 20. Keep this in mind when
switching between batch sizes and be prepared to tweak all the other parameters according
to the batch size used.</p>
</div>
<p>All code-blocks above show pseudocode of how the algorithm looks like. Implementing such
algorithm in Theano can be done as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Minibatch Stochastic Gradient Descent</span>

<span class="c1"># assume loss is a symbolic description of the loss function given</span>
<span class="c1"># the symbolic variables params (shared variable), x_batch, y_batch;</span>

<span class="c1"># compute gradient of loss with respect to params</span>
<span class="n">d_loss_wrt_params</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>

<span class="c1"># compile the MSGD step into a theano function</span>
<span class="n">updates</span> <span class="o">=</span> <span class="p">[(</span><span class="n">params</span><span class="p">,</span> <span class="n">params</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">d_loss_wrt_params</span><span class="p">)]</span>
<span class="n">MSGD</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">function</span><span class="p">([</span><span class="n">x_batch</span><span class="p">,</span><span class="n">y_batch</span><span class="p">],</span> <span class="n">loss</span><span class="p">,</span> <span class="n">updates</span><span class="o">=</span><span class="n">updates</span><span class="p">)</span>

<span class="k">for</span> <span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span> <span class="ow">in</span> <span class="n">train_batches</span><span class="p">:</span>
    <span class="c1"># here x_batch and y_batch are elements of train_batches and</span>
    <span class="c1"># therefore numpy arrays; function MSGD also updates the params</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Current loss is &#39;</span><span class="p">,</span> <span class="n">MSGD</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">stopping_condition_is_met</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">params</span>
</pre></div>
</div>
</section>
<section id="regularization">
<span id="index-11"></span><h3>Regularization<a class="headerlink" href="#regularization" title="Permalink to this heading">¶</a></h3>
<p>There is more to machine learning than optimization.  When we
train our model from data we are trying to prepare it to do well on <em>new</em>
examples, not the ones it has already seen.  The training loop above for MSGD
does not take this into account, and may overfit the training examples.
A way to combat overfitting is through regularization.
There are several techniques for regularization; the ones we will explain
here are L1/L2 regularization and early-stopping.</p>
<section id="l1-and-l2-regularization">
<span id="l1-l2-regularization"></span><span id="index-12"></span><h4>L1 and L2 regularization<a class="headerlink" href="#l1-and-l2-regularization" title="Permalink to this heading">¶</a></h4>
<p>L1 and L2 regularization involve adding an extra term to the loss function,
which penalizes certain parameter configurations. Formally, if our loss function is:</p>
<div class="math notranslate nohighlight">
\[NLL(\theta, \mathcal{D}) = - \sum_{i=0}^{|\mathcal{D}|} \log P(Y=y^{(i)} | x^{(i)}, \theta)\]</div>
<p>then the regularized loss will be:</p>
<div class="math notranslate nohighlight">
\[\begin{split}E(\theta, \mathcal{D}) =  NLL(\theta, \mathcal{D}) + \lambda R(\theta)\\\end{split}\]</div>
<p>or, in our case</p>
<div class="math notranslate nohighlight">
\[E(\theta, \mathcal{D}) =  NLL(\theta, \mathcal{D}) + \lambda||\theta||_p^p\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[||\theta||_p = \left(\sum_{j=0}^{|\theta|}{|\theta_j|^p}\right)^{\frac{1}{p}}\]</div>
<p>which is the <span class="math notranslate nohighlight">\(L_p\)</span> norm of <span class="math notranslate nohighlight">\(\theta\)</span>. <span class="math notranslate nohighlight">\(\lambda\)</span> is a hyper-parameter which
controls the relative importance of the regularization parameter. Commonly used values for p
are 1 and 2, hence the L1/L2 nomenclature. If p=2, then the regularizer is
also called “weight decay”.</p>
<p>In principle, adding a regularization term to the loss will encourage smooth
network mappings in a neural network (by penalizing large values of the
parameters, which decreases the amount of nonlinearity that the
network models). More intuitively, the two terms (NLL and <span class="math notranslate nohighlight">\(R(\theta)\)</span>)
correspond to modelling the data well (NLL) and having “simple” or “smooth”
solutions (<span class="math notranslate nohighlight">\(R(\theta)\)</span>). Thus, minimizing the sum of both will, in
theory, correspond to finding the right trade-off between the fit to the
training data and the “generality” of the solution that is found. To follow
Occam’s razor principle, this minimization should find us the simplest
solution (as measured by our simplicity criterion) that fits the training
data.</p>
<p>Note that the fact that a solution is “simple” does not mean that it will
generalize well. Empirically, it was found that performing such regularization
in the context of neural networks helps with generalization, especially
on small datasets.
The code block below shows how to compute the loss in python when it
contains both a L1 regularization term weighted by <span class="math notranslate nohighlight">\(\lambda_1\)</span> and
L2 regularization term weighted by <span class="math notranslate nohighlight">\(\lambda_2\)</span></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># symbolic Theano variable that represents the L1 regularization term</span>
<span class="n">L1</span>  <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">param</span><span class="p">))</span>

<span class="c1"># symbolic Theano variable that represents the squared L2 term</span>
<span class="n">L2</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">param</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># the loss</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">NLL</span> <span class="o">+</span> <span class="n">lambda_1</span> <span class="o">*</span> <span class="n">L1</span> <span class="o">+</span> <span class="n">lambda_2</span> <span class="o">*</span> <span class="n">L2</span>
</pre></div>
</div>
</section>
<section id="early-stopping">
<span id="opt-early-stopping"></span><span id="index-13"></span><h4>Early-Stopping<a class="headerlink" href="#early-stopping" title="Permalink to this heading">¶</a></h4>
<p>Early-stopping combats overfitting by monitoring the model’s performance on a
<em>validation set</em>.  A validation set is a set of examples that we never use for
gradient descent, but which is also not a part of the <em>test set</em>.  The
validation examples are considered to be representative of future test examples.
We can use them during training because they are not part of the test set.
If the model’s performance ceases to improve sufficiently on the
validation set, or even degrades with further optimization, then the
heuristic implemented here gives up on much further optimization.</p>
<p>The choice of when to stop is a
judgement call and a few heuristics exist, but these tutorials will make use
of a strategy based on a geometrically increasing amount of patience.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># early-stopping parameters</span>
<span class="n">patience</span> <span class="o">=</span> <span class="mi">5000</span>  <span class="c1"># look as this many examples regardless</span>
<span class="n">patience_increase</span> <span class="o">=</span> <span class="mi">2</span>     <span class="c1"># wait this much longer when a new best is</span>
                              <span class="c1"># found</span>
<span class="n">improvement_threshold</span> <span class="o">=</span> <span class="mf">0.995</span>  <span class="c1"># a relative improvement of this much is</span>
                               <span class="c1"># considered significant</span>
<span class="n">validation_frequency</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">n_train_batches</span><span class="p">,</span> <span class="n">patience</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
                              <span class="c1"># go through this many</span>
                              <span class="c1"># minibatches before checking the network</span>
                              <span class="c1"># on the validation set; in this case we</span>
                              <span class="c1"># check every epoch</span>

<span class="n">best_params</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">best_validation_loss</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">inf</span>
<span class="n">test_score</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">clock</span><span class="p">()</span>

<span class="n">done_looping</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">epoch</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">while</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">&lt;</span> <span class="n">n_epochs</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="n">done_looping</span><span class="p">):</span>
    <span class="c1"># Report &quot;1&quot; for first epoch, &quot;n_epochs&quot; for last epoch</span>
    <span class="n">epoch</span> <span class="o">=</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">minibatch_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_train_batches</span><span class="p">):</span>

        <span class="n">d_loss_wrt_params</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># compute gradient</span>
        <span class="n">params</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">d_loss_wrt_params</span> <span class="c1"># gradient descent</span>

        <span class="c1"># iteration number. We want it to start at 0.</span>
        <span class="nb">iter</span> <span class="o">=</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">n_train_batches</span> <span class="o">+</span> <span class="n">minibatch_index</span>
        <span class="c1"># note that if we do `iter % validation_frequency` it will be</span>
        <span class="c1"># true for iter = 0 which we do not want. We want it true for</span>
        <span class="c1"># iter = validation_frequency - 1.</span>
        <span class="k">if</span> <span class="p">(</span><span class="nb">iter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">validation_frequency</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>

            <span class="n">this_validation_loss</span> <span class="o">=</span> <span class="o">...</span> <span class="c1"># compute zero-one loss on validation set</span>

            <span class="k">if</span> <span class="n">this_validation_loss</span> <span class="o">&lt;</span> <span class="n">best_validation_loss</span><span class="p">:</span>

                <span class="c1"># improve patience if loss improvement is good enough</span>
                <span class="k">if</span> <span class="n">this_validation_loss</span> <span class="o">&lt;</span> <span class="n">best_validation_loss</span> <span class="o">*</span> <span class="n">improvement_threshold</span><span class="p">:</span>

                    <span class="n">patience</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">patience</span><span class="p">,</span> <span class="nb">iter</span> <span class="o">*</span> <span class="n">patience_increase</span><span class="p">)</span>
                <span class="n">best_params</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
                <span class="n">best_validation_loss</span> <span class="o">=</span> <span class="n">this_validation_loss</span>

        <span class="k">if</span> <span class="n">patience</span> <span class="o">&lt;=</span> <span class="nb">iter</span><span class="p">:</span>
            <span class="n">done_looping</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">break</span>

<span class="c1"># POSTCONDITION:</span>
<span class="c1"># best_params refers to the best out-of-sample parameters observed during the optimization</span>
</pre></div>
</div>
<p>If we run out of batches of training data before running out of patience, then
we just go back to the beginning of the training set and repeat.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">validation_frequency</span></code> should always be smaller than the
<code class="docutils literal notranslate"><span class="pre">patience</span></code>. The code should check at least two times how it
performs before running out of patience. This is the reason we used
the formulation <code class="docutils literal notranslate"><span class="pre">validation_frequency</span> <span class="pre">=</span> <span class="pre">min(</span> <span class="pre">value,</span> <span class="pre">patience/2.)</span></code></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This algorithm could possibly be improved by using a test of statistical significance
rather than the simple comparison, when deciding whether to increase the
patience.</p>
</div>
</section>
</section>
<section id="testing">
<span id="index-14"></span><h3>Testing<a class="headerlink" href="#testing" title="Permalink to this heading">¶</a></h3>
<p>After the loop exits, the best_params variable refers to the best-performing
model on the validation set.  If we repeat this procedure for another model
class, or even another random initialization, we should use the same
train/valid/test split of the data, and get other best-performing
models.  If we have to choose what the best model class or the best
initialization was, we compare the best_validation_loss for each model.  When
we have finally chosen the model we think is the best (on validation data), we
report that model’s test set performance.  That is the performance we expect on
unseen examples.</p>
</section>
<section id="recap">
<h3>Recap<a class="headerlink" href="#recap" title="Permalink to this heading">¶</a></h3>
<p>That’s it for the optimization section.
The technique of early-stopping requires us to partition the set of examples into three sets
(training <span class="math notranslate nohighlight">\(\mathcal{D}_{train}\)</span>,
validation <span class="math notranslate nohighlight">\(\mathcal{D}_{valid}\)</span>,
test <span class="math notranslate nohighlight">\(\mathcal{D}_{test}\)</span>).
The training set is used for minibatch stochastic gradient descent on the
differentiable approximation of the objective function.
As we perform this gradient descent, we periodically consult the validation set
to see how our model is doing on the real objective function (or at least our
empirical estimate of it).
When we see a good model on the validation set, we save it.
When it has been a long time since seeing a good model, we abandon our search
and return the best parameters found, for evaluation on the test set.</p>
</section>
</section>
<section id="theano-python-tips">
<h2>Theano/Python Tips<a class="headerlink" href="#theano-python-tips" title="Permalink to this heading">¶</a></h2>
<section id="loading-and-saving-models">
<h3>Loading and Saving Models<a class="headerlink" href="#loading-and-saving-models" title="Permalink to this heading">¶</a></h3>
<p>When you’re doing experiments, it can take hours (sometimes days!) for
gradient-descent to find the best parameters.  You will want to save those
weights once you find them.  You may also want to save your current-best
estimates as the search progresses.</p>
<p><strong>Pickle the numpy ndarrays from your shared variables</strong></p>
<p>The best way to save/archive your model’s parameters is to use pickle or
deepcopy the ndarray objects.  So for example, if your parameters are in
shared variables <code class="docutils literal notranslate"><span class="pre">w,</span> <span class="pre">v,</span> <span class="pre">u</span></code>, then your save command should look something
like:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">cPickle</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">save_file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;path&#39;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span>  <span class="c1"># this will overwrite current contents</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cPickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="n">borrow</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">save_file</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># the -1 is for HIGHEST_PROTOCOL</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cPickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="n">borrow</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">save_file</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># .. and it triggers much more efficient</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cPickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">u</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="n">borrow</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">save_file</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># .. storage than numpy&#39;s default</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">save_file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>Then later, you can load your data back like this:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">save_file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;path&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="n">cPickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">save_file</span><span class="p">),</span> <span class="n">borrow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="n">cPickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">save_file</span><span class="p">),</span> <span class="n">borrow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="n">cPickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">save_file</span><span class="p">),</span> <span class="n">borrow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>This technique is a bit verbose, but it is tried and true.  You will be able
to load your data and render it in matplotlib without trouble, years after
saving it.</p>
<p><strong>Do not pickle your training or test functions for long-term storage</strong></p>
<p>Theano functions are compatible with Python’s deepcopy and pickle mechanisms,
but you should not necessarily pickle a Theano function.  If you update your
Theano folder and one of the internal changes, then you may not be able to
un-pickle your model.  Theano is still in active development, and the internal
APIs are subject to change.  So to be on the safe side – do not pickle your
entire training or testing functions for long-term storage.  The pickle
mechanism is aimed at for short-term storage, such as a temp file, or a copy to
another machine in a distributed job.</p>
<p>Read more about <a class="reference external" href="http://deeplearning.net/software/theano/tutorial/loading_and_saving.html">serialization in Theano</a>, or Python’s <a class="reference external" href="http://docs.python.org/library/pickle.html">pickling</a>.</p>
</section>
<section id="plotting-intermediate-results">
<h3>Plotting Intermediate Results<a class="headerlink" href="#plotting-intermediate-results" title="Permalink to this heading">¶</a></h3>
<p>Visualizations can be very powerful tools for understanding what your model or
training algorithm is doing.  You might be tempted to insert <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code>
plotting commands, or <code class="docutils literal notranslate"><span class="pre">PIL</span></code> image-rendering commands into your model-training
script.  However, later you will observe something interesting in one of those
pre-rendered images and want to investigate something that isn’t clear from
the pictures.  You’ll wished you had saved the original model.</p>
<p><strong>If you have enough disk space, your training script should save intermediate models and  a visualization
script should process those saved models.</strong></p>
<p>You already have a model-saving function right?  Just use it again to save
these intermediate models.</p>
<p>Libraries you’ll want to know about: Python Image Library (<a class="reference external" href="http://www.pythonware.com/products/pil">PIL</a>), <a class="reference external" href="http://matplotlib.sourceforge.net">matplotlib</a>.</p>
</section>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <div>
    <h3><a href="contents.html">Table of Contents</a></h3>
    <ul>
<li><a class="reference internal" href="#">Getting Started</a><ul>
<li><a class="reference internal" href="#index-0">Download</a></li>
<li><a class="reference internal" href="#index-1">Datasets</a><ul>
<li><a class="reference internal" href="#mnist-dataset">MNIST Dataset</a></li>
</ul>
</li>
<li><a class="reference internal" href="#notation">Notation</a><ul>
<li><a class="reference internal" href="#dataset-notation">Dataset notation</a></li>
<li><a class="reference internal" href="#math-conventions">Math Conventions</a></li>
<li><a class="reference internal" href="#list-of-symbols-and-acronyms">List of Symbols and acronyms</a></li>
<li><a class="reference internal" href="#python-namespaces">Python Namespaces</a></li>
</ul>
</li>
<li><a class="reference internal" href="#a-primer-on-supervised-optimization-for-deep-learning">A Primer on Supervised Optimization for Deep Learning</a><ul>
<li><a class="reference internal" href="#learning-a-classifier">Learning a Classifier</a><ul>
<li><a class="reference internal" href="#zero-one-loss">Zero-One Loss</a></li>
<li><a class="reference internal" href="#negative-log-likelihood-loss">Negative Log-Likelihood Loss</a></li>
</ul>
</li>
<li><a class="reference internal" href="#stochastic-gradient-descent">Stochastic Gradient Descent</a></li>
<li><a class="reference internal" href="#regularization">Regularization</a><ul>
<li><a class="reference internal" href="#l1-and-l2-regularization">L1 and L2 regularization</a></li>
<li><a class="reference internal" href="#early-stopping">Early-Stopping</a></li>
</ul>
</li>
<li><a class="reference internal" href="#testing">Testing</a></li>
<li><a class="reference internal" href="#recap">Recap</a></li>
</ul>
</li>
<li><a class="reference internal" href="#theano-python-tips">Theano/Python Tips</a><ul>
<li><a class="reference internal" href="#loading-and-saving-models">Loading and Saving Models</a></li>
<li><a class="reference internal" href="#plotting-intermediate-results">Plotting Intermediate Results</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  </div>
  <div>
    <h4>Previous topic</h4>
    <p class="topless"><a href="index.html"
                          title="previous chapter">Deep Learning Tutorials</a></p>
  </div>
  <div>
    <h4>Next topic</h4>
    <p class="topless"><a href="logreg.html"
                          title="next chapter">Classifying MNIST digits using Logistic Regression</a></p>
  </div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/gettingstarted.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="logreg.html" title="Classifying MNIST digits using Logistic Regression"
             >next</a> |</li>
        <li class="right" >
          <a href="index.html" title="Deep Learning Tutorials"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="contents.html">DeepLearning 0.1 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Getting Started</a></li> 
      </ul>
    </div>

    <div class="footer" role="contentinfo">
        &#169; Copyright 2008--2010, LISA lab.
      Last updated on May 11, 2023.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 6.1.3.
    </div>
<script type="text/javascript">
  (function() {
    var ga = document.createElement('script');
    ga.src = ('https:' == document.location.protocol ?
              'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    ga.setAttribute('async', 'true');
    document.documentElement.firstChild.appendChild(ga);
  })();
</script>

  </body>
</html>