
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Hybrid Monte-Carlo Sampling &#8212; DeepLearning 0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinxdoc.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Recurrent Neural Networks with Word Embeddings" href="rnnslu.html" />
    <link rel="prev" title="Deep Belief Networks" href="DBN.html" />
 
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-168290-9']);
  _gaq.push(['_trackPageview']);
</script>

  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="rnnslu.html" title="Recurrent Neural Networks with Word Embeddings"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="DBN.html" title="Deep Belief Networks"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="contents.html">DeepLearning 0.1 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Hybrid Monte-Carlo Sampling</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="hybrid-monte-carlo-sampling">
<span id="hmc"></span><h1>Hybrid Monte-Carlo Sampling<a class="headerlink" href="#hybrid-monte-carlo-sampling" title="Permalink to this heading">¶</a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This is an advanced tutorial, which shows how one can implemented Hybrid
Monte-Carlo (HMC) sampling using Theano. We assume the reader is already
familiar with Theano and energy-based models such as the RBM.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The code for this section is available for download <a class="reference external" href="http://deeplearning.net/tutorial/code/hmc/hmc.py">here</a>.</p>
</div>
<section id="theory">
<h2>Theory<a class="headerlink" href="#theory" title="Permalink to this heading">¶</a></h2>
<p>Maximum likelihood learning of energy-based models requires a robust algorithm
to sample negative phase particles (see Eq.(4) of the <a class="reference internal" href="rbm.html"><span class="doc">Restricted Boltzmann Machines (RBM)</span></a> tutorial).
When training RBMs with CD or PCD, this is typically done with block Gibbs
sampling, where the conditional distributions <span class="math">p(h|v)</span> and
<span class="math">p(v|h)</span> are used as the transition operators of the Markov chain.</p>
<p>In certain cases however, these conditional distributions might be difficult
to sample from (i.e. requiring expensive matrix inversions, as in the case of
the “mean-covariance RBM”). Also, even if Gibbs sampling can be done
efficiently, it nevertheless operates via a random walk which might not be
statistically efficient for some distributions.
In this context, and when sampling from continuous variables, Hybrid Monte
Carlo (HMC) can prove to be a powerful tool <a class="reference internal" href="#duane87" id="id1"><span>[Duane87]</span></a>. It avoids random walk
behavior by simulating a physical system governed by Hamiltonian dynamics,
potentially avoiding tricky conditional distributions in the process.</p>
<p>In HMC, model samples are obtained by simulating a physical system, where
particles move about a high-dimensional landscape, subject to potential and
kinetic energies.  Adapting the notation from <a class="reference internal" href="#neal93" id="id2"><span>[Neal93]</span></a>, particles are
characterized by a position vector or state <span class="math">s \in \mathcal{R}^D</span> and
velocity vector <span class="math">\phi \in \mathcal{R}^D</span>. The combined state of a
particle is denoted as <span class="math">\chi=(s,\phi)</span>. The Hamiltonian is then defined
as the sum of potential energy <span class="math">E(s)</span> (same energy function defined by
energy-based models) and kinetic energy <span class="math">K(\phi)</span>, as follows:</p>
<div class="math">
<p><span class="math">\mathcal{H}(s,\phi) = E(s) + K(\phi)
                          = E(s) + \frac{1}{2} \sum_i \phi_i^2</span></p>
</div><p>Instead of sampling <span class="math">p(s)</span> directly, HMC operates by sampling from the
canonical distribution
<span class="math">p(s,\phi) = \frac{1}{Z} \exp(-\mathcal{H}(s,\phi))=p(s)p(\phi)</span>.
Because the two variables are independent, marginalizing over
<span class="math">\phi</span> is trivial and recovers the original distribution of
interest.</p>
<p><strong>Hamiltonian Dynamics</strong></p>
<p>State <span class="math">s</span> and velocity <span class="math">\phi</span> are modified such that
<span class="math">\mathcal{H}(s,\phi)</span> remains constant throughout the simulation.
The differential equations are given by:</p>
<div class="math" id="equation-ds-dt">
<p><span class="eqno">(1)<a class="headerlink" href="#equation-ds-dt" title="Permalink to this equation">¶</a></span><span class="math">\frac{ds_i}{dt} &amp;= \frac{\partial \mathcal{H}}{\partial \phi_i} = \phi_i \\
\frac{d\phi_i}{dt} &amp;= - \frac{\partial \mathcal{H}}{\partial s_i}
                 = - \frac{\partial E}{\partial s_i}</span></p>
</div><p>As shown in <a class="reference internal" href="#neal93" id="id3"><span>[Neal93]</span></a>, the above transformation preserves volume and is
reversible. The above dynamics can thus be used as transition operators of a
Markov chain and will leave <span class="math">p(s,\phi)</span> invariant. That chain by itself
is not ergodic however, since simulating the dynamics maintains a fixed
Hamiltonian <span class="math">\mathcal{H}(s,\phi)</span>.
HMC thus alternates hamiltonian dynamic steps, with Gibbs sampling of the
velocity. Because <span class="math">p(s)</span> and <span class="math">p(\phi)</span> are independent, sampling
<span class="math">\phi_{new} \sim p(\phi|s)</span> is trivial since <span class="math">p(\phi|s)=p(\phi)</span>,
where <span class="math">p(\phi)</span> is often taken to be the uni-variate Gaussian.</p>
<p><strong>The Leap-Frog Algorithm</strong></p>
<p>In practice, we cannot simulate Hamiltonian dynamics exactly because of the
problem of time discretization. There are several ways one can do this. To
maintain invariance of the Markov chain however, care must be taken to
preserve the properties of volume conservation and time reversibility.  The
<strong>leap-frog algorithm</strong> maintains these properties and operates in 3 steps:</p>
<div class="math" id="equation-leap-frog">
<p><span class="eqno">(2)<a class="headerlink" href="#equation-leap-frog" title="Permalink to this equation">¶</a></span><span class="math">\phi_i(t + \epsilon/2) &amp;= \phi_i(t) - \frac{\epsilon}{2} \frac{\partial{}}{\partial s_i} E(s(t)) \\
s_i(t + \epsilon) &amp;= s_i(t) + \epsilon \phi_i(t + \epsilon/2) \\
\phi_i(t + \epsilon) &amp;= \phi_i(t + \epsilon/2) - \frac{\epsilon}{2} \frac{\partial{}}{\partial s_i} E(s(t + \epsilon)) \\</span></p>
</div><p>We thus perform a half-step update of the velocity at time
<span class="math">t+\epsilon/2</span>, which is then used to compute <span class="math">s(t + \epsilon)</span>
and <span class="math">\phi(t + \epsilon)</span>.</p>
<p><strong>Accept / Reject</strong></p>
<p>In practice, using finite stepsizes <span class="math">\epsilon</span> will not preserve
<span class="math">\mathcal{H}(s,\phi)</span> exactly and will introduce bias in the simulation.
Also, rounding errors due to the use of floating point numbers means that the
above transformation will not be perfectly reversible.</p>
<p>HMC cancels these effects <strong>exactly</strong> by adding a Metropolis accept/reject
stage, after <span class="math">n</span> leapfrog steps. The new state <span class="math">\chi' = (s',\phi')</span> is
accepted with probability <span class="math">p_{acc}(\chi,\chi')</span>, defined as:</p>
<div class="math">
<p><span class="math">p_{acc}(\chi,\chi') = min \left( 1, \frac{\exp(-\mathcal{H}(s',\phi')}{\exp(-\mathcal{H}(s,\phi)} \right)</span></p>
</div><p><strong>HMC Algorithm</strong></p>
<p>In this tutorial, we obtain a new HMC sample as follows:</p>
<ol class="arabic simple">
<li><p>sample a new velocity from a univariate Gaussian distribution</p></li>
<li><p>perform <span class="math">n</span> leapfrog steps to obtain the new state <span class="math">\chi'</span></p></li>
<li><p>perform accept/reject move of <span class="math">\chi'</span></p></li>
</ol>
</section>
<section id="implementing-hmc-using-theano">
<h2>Implementing HMC Using Theano<a class="headerlink" href="#implementing-hmc-using-theano" title="Permalink to this heading">¶</a></h2>
<p>In Theano, update dictionaries and shared variables provide a natural way to
implement a sampling algorithm. The current state of the sampler can be
represented as a Theano shared variable, with HMC updates being implemented by
the updates list of a Theano function.</p>
<p>We breakdown the HMC algorithm into the following sub-components:</p>
<ul class="simple">
<li><p><span class="math">simulate\_dynamics</span>: a symbolic Python function which, given an initial position and velocity, will perform <span class="math">n\_steps</span> leapfrog updates and return the symbolic variables for the proposed state <span class="math">\chi'</span>.</p></li>
<li><p><span class="math">hmc\_move</span>: a symbolic Python function which given a starting position,
generates <span class="math">\chi</span> by randomly sampling a velocity vector. It then
calls <span class="math">simulate\_dynamics</span> and determines whether the transition <span class="math">\chi
\rightarrow \chi'</span> is to be accepted.</p></li>
<li><p><span class="math">hmc\_updates</span>: a Python function which, given the symbolic outputs of <span class="math">hmc\_move</span>,
generates the list of updates for a single iteration of HMC.</p></li>
<li><p><span class="math">HMC\_sampler</span>: a Python helper class which wraps everything together.</p></li>
</ul>
<p><strong>simulate_dynamics</strong></p>
<p>To perform <span class="math">n</span> leapfrog steps, we first need to define a function over
which <span class="math">Scan</span> can iterate over. Instead of implementing Eq. <a class="reference internal" href="#equation-leap-frog">(2)</a>
verbatim, notice that we can obtain <span class="math">s(t + n \epsilon)</span> and
<span class="math">\phi(t + n \epsilon)</span> by performing an initial half-step update for
<span class="math">\phi</span>, followed by <span class="math">n</span> full-step updates for <span class="math">s,\phi</span> and
one last half-step update for <span class="math">\phi</span>. In loop form, this gives:</p>
<div class="math" id="equation-leap-frog2">
<p><span class="eqno">(3)<a class="headerlink" href="#equation-leap-frog2" title="Permalink to this equation">¶</a></span><span class="math">&amp; \phi_i(t + \epsilon/2) = \phi_i(t) -
   \frac{\epsilon}{2} \frac{\partial{}}{\partial s_i} E(s(t)) \\
&amp; s_i(t + \epsilon) = s_i(t) + \epsilon \phi_i(t + \epsilon/2) \\
&amp; \text{For } m \in [2,n]\text{, perform full updates: } \\
&amp; \qquad
  \phi_i(t + (m - 1/2)\epsilon) = \phi_i(t + (m-3/2)\epsilon) -
      \epsilon \frac{\partial{}}{\partial s_i} E(s(t + (m-1)\epsilon)) \\
&amp; \qquad
  s_i(t + m\epsilon) = s_i(t) + \epsilon \phi_i(t + (m-1/2)\epsilon) \\
&amp; \phi_i(t + n\epsilon) = \phi_i(t + (n-1/2)\epsilon) -
     \frac{\epsilon}{2} \frac{\partial{}}{\partial s_i} E(s(t + n\epsilon)) \\</span></p>
</div><p>The inner-loop defined above is implemented by the following <span class="math">leapfrog</span>
function, with <span class="math">pos</span>, <span class="math">vel</span> and <span class="math">step</span> replacing <span class="math">s,\phi</span> and <span class="math">\epsilon</span>
respectively.</p>
<p>The <span class="math">simulate\_dynamics</span> function performs the full algorithm of Eqs.
<a class="reference internal" href="#equation-leap-frog2">(3)</a>. We start with the initial half-step update of <span class="math">\phi</span>
and full-step of <span class="math">s</span>, and then scan over the <span class="math">leapfrog</span> method
<span class="math">n\_steps-1</span> times.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">simulate_dynamics</span><span class="p">(</span><span class="n">initial_pos</span><span class="p">,</span> <span class="n">initial_vel</span><span class="p">,</span> <span class="n">stepsize</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">,</span> <span class="n">energy_fn</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return final (position, velocity) obtained after an `n_steps` leapfrog</span>
<span class="sd">    updates, using Hamiltonian dynamics.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    initial_pos: shared theano matrix</span>
<span class="sd">        Initial position at which to start the simulation</span>
<span class="sd">    initial_vel: shared theano matrix</span>
<span class="sd">        Initial velocity of particles</span>
<span class="sd">    stepsize: shared theano scalar</span>
<span class="sd">        Scalar value controlling amount by which to move</span>
<span class="sd">    energy_fn: python function</span>
<span class="sd">        Python function, operating on symbolic theano variables, used to</span>
<span class="sd">        compute the potential energy at a given position.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    rval1: theano matrix</span>
<span class="sd">        Final positions obtained after simulation</span>
<span class="sd">    rval2: theano matrix</span>
<span class="sd">        Final velocity obtained after simulation</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">leapfrog</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">vel</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Inside loop of Scan. Performs one step of leapfrog update, using</span>
<span class="sd">        Hamiltonian dynamics.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        pos: theano matrix</span>
<span class="sd">            in leapfrog update equations, represents pos(t), position at time t</span>
<span class="sd">        vel: theano matrix</span>
<span class="sd">            in leapfrog update equations, represents vel(t - stepsize/2),</span>
<span class="sd">            velocity at time (t - stepsize/2)</span>
<span class="sd">        step: theano scalar</span>
<span class="sd">            scalar value controlling amount by which to move</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        rval1: [theano matrix, theano matrix]</span>
<span class="sd">            Symbolic theano matrices for new position pos(t + stepsize), and</span>
<span class="sd">            velocity vel(t + stepsize/2)</span>
<span class="sd">        rval2: dictionary</span>
<span class="sd">            Dictionary of updates for the Scan Op</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># from pos(t) and vel(t-stepsize//2), compute vel(t+stepsize//2)</span>
        <span class="n">dE_dpos</span> <span class="o">=</span> <span class="n">TT</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">energy_fn</span><span class="p">(</span><span class="n">pos</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="n">pos</span><span class="p">)</span>
        <span class="n">new_vel</span> <span class="o">=</span> <span class="n">vel</span> <span class="o">-</span> <span class="n">step</span> <span class="o">*</span> <span class="n">dE_dpos</span>
        <span class="c1"># from vel(t+stepsize//2) compute pos(t+stepsize)</span>
        <span class="n">new_pos</span> <span class="o">=</span> <span class="n">pos</span> <span class="o">+</span> <span class="n">step</span> <span class="o">*</span> <span class="n">new_vel</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">new_pos</span><span class="p">,</span> <span class="n">new_vel</span><span class="p">],</span> <span class="p">{}</span>

    <span class="c1"># compute velocity at time-step: t + stepsize//2</span>
    <span class="n">initial_energy</span> <span class="o">=</span> <span class="n">energy_fn</span><span class="p">(</span><span class="n">initial_pos</span><span class="p">)</span>
    <span class="n">dE_dpos</span> <span class="o">=</span> <span class="n">TT</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">initial_energy</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="n">initial_pos</span><span class="p">)</span>
    <span class="n">vel_half_step</span> <span class="o">=</span> <span class="n">initial_vel</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">stepsize</span> <span class="o">*</span> <span class="n">dE_dpos</span>

    <span class="c1"># compute position at time-step: t + stepsize</span>
    <span class="n">pos_full_step</span> <span class="o">=</span> <span class="n">initial_pos</span> <span class="o">+</span> <span class="n">stepsize</span> <span class="o">*</span> <span class="n">vel_half_step</span>

    <span class="c1"># perform leapfrog updates: the scan op is used to repeatedly compute</span>
    <span class="c1"># vel(t + (m-1/2)*stepsize) and pos(t + m*stepsize) for m in [2,n_steps].</span>
    <span class="p">(</span><span class="n">all_pos</span><span class="p">,</span> <span class="n">all_vel</span><span class="p">),</span> <span class="n">scan_updates</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span>
        <span class="n">leapfrog</span><span class="p">,</span>
        <span class="n">outputs_info</span><span class="o">=</span><span class="p">[</span>
            <span class="nb">dict</span><span class="p">(</span><span class="n">initial</span><span class="o">=</span><span class="n">pos_full_step</span><span class="p">),</span>
            <span class="nb">dict</span><span class="p">(</span><span class="n">initial</span><span class="o">=</span><span class="n">vel_half_step</span><span class="p">),</span>
        <span class="p">],</span>
        <span class="n">non_sequences</span><span class="o">=</span><span class="p">[</span><span class="n">stepsize</span><span class="p">],</span>
        <span class="n">n_steps</span><span class="o">=</span><span class="n">n_steps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">final_pos</span> <span class="o">=</span> <span class="n">all_pos</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">final_vel</span> <span class="o">=</span> <span class="n">all_vel</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="c1"># NOTE: Scan always returns an updates dictionary, in case the</span>
    <span class="c1"># scanned function draws samples from a RandomStream. These</span>
    <span class="c1"># updates must then be used when compiling the Theano function, to</span>
    <span class="c1"># avoid drawing the same random numbers each time the function is</span>
    <span class="c1"># called. In this case however, we consciously ignore</span>
    <span class="c1"># &quot;scan_updates&quot; because we know it is empty.</span>
    <span class="k">assert</span> <span class="ow">not</span> <span class="n">scan_updates</span>

    <span class="c1"># The last velocity returned by scan is vel(t +</span>
    <span class="c1"># (n_steps - 1 / 2) * stepsize) We therefore perform one more half-step</span>
    <span class="c1"># to return vel(t + n_steps * stepsize)</span>
    <span class="n">energy</span> <span class="o">=</span> <span class="n">energy_fn</span><span class="p">(</span><span class="n">final_pos</span><span class="p">)</span>
    <span class="n">final_vel</span> <span class="o">=</span> <span class="n">final_vel</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">stepsize</span> <span class="o">*</span> <span class="n">TT</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">energy</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="n">final_pos</span><span class="p">)</span>

    <span class="c1"># return new proposal state</span>
    <span class="k">return</span> <span class="n">final_pos</span><span class="p">,</span> <span class="n">final_vel</span>
</pre></div>
</div>
<p>A final half-step is performed to compute <span class="math">\phi(t+n\epsilon)</span>, and the
final proposed state <span class="math">\chi'</span> is returned.</p>
<p><strong>hmc_move</strong></p>
<p>The <span class="math">hmc\_move</span> function implements the remaining steps (steps 1 and 3) of an
HMC move proposal (while wrapping the <span class="math">simulate\_dynamics</span> function). Given a
matrix of initial states <span class="math">s \in \mathcal{R}^{N \times D}</span> (<span class="math">positions</span>) and
energy function <span class="math">E(s)</span> (<span class="math">energy\_fn</span>), it defines the symbolic graph for
computing <span class="math">n\_steps</span> of HMC, using a given <span class="math">stepsize</span>. The function prototype
is as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">hmc_move</span><span class="p">(</span><span class="n">s_rng</span><span class="p">,</span> <span class="n">positions</span><span class="p">,</span> <span class="n">energy_fn</span><span class="p">,</span> <span class="n">stepsize</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function performs one-step of Hybrid Monte-Carlo sampling. We start by</span>
<span class="sd">    sampling a random velocity from a univariate Gaussian distribution, perform</span>
<span class="sd">    `n_steps` leap-frog updates using Hamiltonian dynamics and accept-reject</span>
<span class="sd">    using Metropolis-Hastings.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    s_rng: theano shared random stream</span>
<span class="sd">        Symbolic random number generator used to draw random velocity and</span>
<span class="sd">        perform accept-reject move.</span>
<span class="sd">    positions: shared theano matrix</span>
<span class="sd">        Symbolic matrix whose rows are position vectors.</span>
<span class="sd">    energy_fn: python function</span>
<span class="sd">        Python function, operating on symbolic theano variables, used to</span>
<span class="sd">        compute the potential energy at a given position.</span>
<span class="sd">    stepsize:  shared theano scalar</span>
<span class="sd">        Shared variable containing the stepsize to use for `n_steps` of HMC</span>
<span class="sd">        simulation steps.</span>
<span class="sd">    n_steps: integer</span>
<span class="sd">        Number of HMC steps to perform before proposing a new position.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    rval1: boolean</span>
<span class="sd">        True if move is accepted, False otherwise</span>
<span class="sd">    rval2: theano matrix</span>
<span class="sd">        Matrix whose rows contain the proposed &quot;new position&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
</pre></div>
</div>
<p>We start by sampling random velocities, using the provided shared RandomStream
object. Velocities are sampled independently for each dimension and for each
particle under simulation, yielding a <span class="math">N \times D</span> matrix.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># sample random velocity</span>
    <span class="n">initial_vel</span> <span class="o">=</span> <span class="n">s_rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">positions</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<p>Since we now have an initial position and velocity, we can now call the
<span class="math">simulate\_dynamics</span> to obtain the proposal for the new state <span class="math">\chi'</span>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># perform simulation of particles subject to Hamiltonian dynamics</span>
    <span class="n">final_pos</span><span class="p">,</span> <span class="n">final_vel</span> <span class="o">=</span> <span class="n">simulate_dynamics</span><span class="p">(</span>
        <span class="n">initial_pos</span><span class="o">=</span><span class="n">positions</span><span class="p">,</span>
        <span class="n">initial_vel</span><span class="o">=</span><span class="n">initial_vel</span><span class="p">,</span>
        <span class="n">stepsize</span><span class="o">=</span><span class="n">stepsize</span><span class="p">,</span>
        <span class="n">n_steps</span><span class="o">=</span><span class="n">n_steps</span><span class="p">,</span>
        <span class="n">energy_fn</span><span class="o">=</span><span class="n">energy_fn</span>
    <span class="p">)</span>
</pre></div>
</div>
<p>We then accept/reject the proposed state based on the Metropolis algorithm.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># accept/reject the proposed move based on the joint distribution</span>
    <span class="n">accept</span> <span class="o">=</span> <span class="n">metropolis_hastings_accept</span><span class="p">(</span>
        <span class="n">energy_prev</span><span class="o">=</span><span class="n">hamiltonian</span><span class="p">(</span><span class="n">positions</span><span class="p">,</span> <span class="n">initial_vel</span><span class="p">,</span> <span class="n">energy_fn</span><span class="p">),</span>
        <span class="n">energy_next</span><span class="o">=</span><span class="n">hamiltonian</span><span class="p">(</span><span class="n">final_pos</span><span class="p">,</span> <span class="n">final_vel</span><span class="p">,</span> <span class="n">energy_fn</span><span class="p">),</span>
        <span class="n">s_rng</span><span class="o">=</span><span class="n">s_rng</span>
    <span class="p">)</span>
</pre></div>
</div>
<p>where <span class="math">metropolis\_hastings\_accept</span> and <span class="math">hamiltonian</span> are helper functions,
defined as follows.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">metropolis_hastings_accept</span><span class="p">(</span><span class="n">energy_prev</span><span class="p">,</span> <span class="n">energy_next</span><span class="p">,</span> <span class="n">s_rng</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs a Metropolis-Hastings accept-reject move.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    energy_prev: theano vector</span>
<span class="sd">        Symbolic theano tensor which contains the energy associated with the</span>
<span class="sd">        configuration at time-step t.</span>
<span class="sd">    energy_next: theano vector</span>
<span class="sd">        Symbolic theano tensor which contains the energy associated with the</span>
<span class="sd">        proposed configuration at time-step t+1.</span>
<span class="sd">    s_rng: theano.tensor.shared_randomstreams.RandomStreams</span>
<span class="sd">        Theano shared random stream object used to generate the random number</span>
<span class="sd">        used in proposal.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    return: boolean</span>
<span class="sd">        True if move is accepted, False otherwise</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ediff</span> <span class="o">=</span> <span class="n">energy_prev</span> <span class="o">-</span> <span class="n">energy_next</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">TT</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">ediff</span><span class="p">)</span> <span class="o">-</span> <span class="n">s_rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">energy_prev</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span> <span class="o">&gt;=</span> <span class="mi">0</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">hamiltonian</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">vel</span><span class="p">,</span> <span class="n">energy_fn</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the Hamiltonian (sum of potential and kinetic energy) for the given</span>
<span class="sd">    velocity and position.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pos: theano matrix</span>
<span class="sd">        Symbolic matrix whose rows are position vectors.</span>
<span class="sd">    vel: theano matrix</span>
<span class="sd">        Symbolic matrix whose rows are velocity vectors.</span>
<span class="sd">    energy_fn: python function</span>
<span class="sd">        Python function, operating on symbolic theano variables, used tox</span>
<span class="sd">        compute the potential energy at a given position.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    return: theano vector</span>
<span class="sd">        Vector whose i-th entry is the Hamiltonian at position pos[i] and</span>
<span class="sd">        velocity vel[i].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># assuming mass is 1</span>
    <span class="k">return</span> <span class="n">energy_fn</span><span class="p">(</span><span class="n">pos</span><span class="p">)</span> <span class="o">+</span> <span class="n">kinetic_energy</span><span class="p">(</span><span class="n">vel</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">kinetic_energy</span><span class="p">(</span><span class="n">vel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns the kinetic energy associated with the given velocity</span>
<span class="sd">    and mass of 1.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    vel: theano matrix</span>
<span class="sd">        Symbolic matrix whose rows are velocity vectors.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    return: theano vector</span>
<span class="sd">        Vector whose i-th entry is the kinetic entry associated with vel[i].</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">vel</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p><span class="math">hmc\_move</span> finally returns the tuple <span class="math">(accept, final\_pos)</span>. <span class="math">accept</span> is a
symbolic boolean variable indicating whether or not the new state <span class="math">final\_pos</span>
should be used or not.</p>
<p><strong>hmc_updates</strong></p>
<p>The purpose of <span class="math">hmc\_updates</span> is to generate the list of updates to
perform, whenever our HMC sampling function is called. <span class="math">hmc\_updates</span> thus
receives as parameters, a series of shared variables to update (<span class="math">positions</span>, <span class="math">stepsize</span> and
<span class="math">avg\_acceptance\_rate</span>), and the parameters required to compute their new
state.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">hmc_updates</span><span class="p">(</span><span class="n">positions</span><span class="p">,</span> <span class="n">stepsize</span><span class="p">,</span> <span class="n">avg_acceptance_rate</span><span class="p">,</span> <span class="n">final_pos</span><span class="p">,</span> <span class="n">accept</span><span class="p">,</span>
                <span class="n">target_acceptance_rate</span><span class="p">,</span> <span class="n">stepsize_inc</span><span class="p">,</span> <span class="n">stepsize_dec</span><span class="p">,</span>
                <span class="n">stepsize_min</span><span class="p">,</span> <span class="n">stepsize_max</span><span class="p">,</span> <span class="n">avg_acceptance_slowness</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;This function is executed after `n_steps` of HMC sampling</span>
<span class="sd">    (`hmc_move` function). It creates the updates dictionary used by</span>
<span class="sd">    the `simulate` function. It takes care of updating: the position</span>
<span class="sd">    (if the move is accepted), the stepsize (to track a given target</span>
<span class="sd">    acceptance rate) and the average acceptance rate (computed as a</span>
<span class="sd">    moving average).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    positions: shared variable, theano matrix</span>
<span class="sd">        Shared theano matrix whose rows contain the old position</span>
<span class="sd">    stepsize: shared variable, theano scalar</span>
<span class="sd">        Shared theano scalar containing current step size</span>
<span class="sd">    avg_acceptance_rate: shared variable, theano scalar</span>
<span class="sd">        Shared theano scalar containing the current average acceptance rate</span>
<span class="sd">    final_pos: shared variable, theano matrix</span>
<span class="sd">        Shared theano matrix whose rows contain the new position</span>
<span class="sd">    accept: theano scalar</span>
<span class="sd">        Boolean-type variable representing whether or not the proposed HMC move</span>
<span class="sd">        should be accepted or not.</span>
<span class="sd">    target_acceptance_rate: float</span>
<span class="sd">        The stepsize is modified in order to track this target acceptance rate.</span>
<span class="sd">    stepsize_inc: float</span>
<span class="sd">        Amount by which to increment stepsize when acceptance rate is too high.</span>
<span class="sd">    stepsize_dec: float</span>
<span class="sd">        Amount by which to decrement stepsize when acceptance rate is too low.</span>
<span class="sd">    stepsize_min: float</span>
<span class="sd">        Lower-bound on `stepsize`.</span>
<span class="sd">    stepsize_min: float</span>
<span class="sd">        Upper-bound on `stepsize`.</span>
<span class="sd">    avg_acceptance_slowness: float</span>
<span class="sd">        Average acceptance rate is computed as an exponential moving average.</span>
<span class="sd">        (1-avg_acceptance_slowness) is the weight given to the newest</span>
<span class="sd">        observation.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    rval1: dictionary-like</span>
<span class="sd">        A dictionary of updates to be used by the `HMC_Sampler.simulate`</span>
<span class="sd">        function.  The updates target the position, stepsize and average</span>
<span class="sd">        acceptance rate.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># POSITION UPDATES #</span>
    <span class="c1"># broadcast `accept` scalar to tensor with the same dimensions as</span>
    <span class="c1"># final_pos.</span>
    <span class="n">accept_matrix</span> <span class="o">=</span> <span class="n">accept</span><span class="o">.</span><span class="n">dimshuffle</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">*</span><span class="p">((</span><span class="s1">&#39;x&#39;</span><span class="p">,)</span> <span class="o">*</span> <span class="p">(</span><span class="n">final_pos</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)))</span>
    <span class="c1"># if accept is True, update to `final_pos` else stay put</span>
    <span class="n">new_positions</span> <span class="o">=</span> <span class="n">TT</span><span class="o">.</span><span class="n">switch</span><span class="p">(</span><span class="n">accept_matrix</span><span class="p">,</span> <span class="n">final_pos</span><span class="p">,</span> <span class="n">positions</span><span class="p">)</span>
</pre></div>
</div>
<p>Using the above code, the dictionary <span class="math">{positions: new\_positions}</span> can be used
to update the state of the sampler with either (1) the new state <span class="math">final\_pos</span>
if <span class="math">accept</span> is True, or (2) the old state if <span class="math">accept</span> is False.  This
conditional assignment is performed by the <a class="reference external" href="http://deeplearning.net/software/theano/library/tensor/basic.html#tensor.switch">switch</a> op.</p>
<p><span class="math">switch</span> expects as its first argument, a boolean mask with the same
broadcastable dimensions as the second and third argument. Since <span class="math">accept</span> is
scalar-valued, we must first use <a class="reference external" href="http://deeplearning.net/software/theano/library/tensor/basic.html#tensor._tensor_py_operators.dimshuffle">dimshuffle</a> to transform it to a tensor with
<span class="math">final\_pos.ndim</span> broadcastable dimensions (<span class="math">accept\_matrix</span>).</p>
<p><span class="math">hmc\_updates</span> additionally implements an adaptive version of HMC, as
implemented in the accompanying code to <a class="reference internal" href="references.html#ranzato10" id="id4"><span>[Ranzato10]</span></a>. We start by tracking the
average acceptance rate of the HMC move proposals (across many simulations),
using an exponential moving average with time constant
<span class="math">1-avg\_acceptance\_slowness</span>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># ACCEPT RATE UPDATES #</span>
    <span class="c1"># perform exponential moving average</span>
    <span class="n">mean_dtype</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">scalar</span><span class="o">.</span><span class="n">upcast</span><span class="p">(</span><span class="n">accept</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">avg_acceptance_rate</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">new_acceptance_rate</span> <span class="o">=</span> <span class="n">TT</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
        <span class="n">avg_acceptance_slowness</span> <span class="o">*</span> <span class="n">avg_acceptance_rate</span><span class="p">,</span>
        <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">avg_acceptance_slowness</span><span class="p">)</span> <span class="o">*</span> <span class="n">accept</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">mean_dtype</span><span class="p">))</span>
</pre></div>
</div>
<p>If the average acceptance rate is larger than the <span class="math">target\_acceptance\_rate</span>, we
increase the <span class="math">stepsize</span> by a factor of <span class="math">stepsize\_inc</span> in order to increase the
mixing rate of our chain. If the average acceptance rate is too low however,
<span class="math">stepsize</span> is decreased by a factor of <span class="math">stepsize\_dec</span>, yielding a more
conservative mixing rate. The <a class="reference external" href="http://deeplearning.net/software/theano/library/tensor/basic.html#tensor.clip">clip</a> op allows us to maintain the <span class="math">stepsize</span>
in the range [<span class="math">stepsize\_min</span>, <span class="math">stepsize\_max</span>].</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="c1"># STEPSIZE UPDATES #</span>
    <span class="c1"># if acceptance rate is too low, our sampler is too &quot;noisy&quot; and we reduce</span>
    <span class="c1"># the stepsize. If it is too high, our sampler is too conservative, we can</span>
    <span class="c1"># get away with a larger stepsize (resulting in better mixing).</span>
    <span class="n">_new_stepsize</span> <span class="o">=</span> <span class="n">TT</span><span class="o">.</span><span class="n">switch</span><span class="p">(</span><span class="n">avg_acceptance_rate</span> <span class="o">&gt;</span> <span class="n">target_acceptance_rate</span><span class="p">,</span>
                              <span class="n">stepsize</span> <span class="o">*</span> <span class="n">stepsize_inc</span><span class="p">,</span> <span class="n">stepsize</span> <span class="o">*</span> <span class="n">stepsize_dec</span><span class="p">)</span>
    <span class="c1"># maintain stepsize in [stepsize_min, stepsize_max]</span>
    <span class="n">new_stepsize</span> <span class="o">=</span> <span class="n">TT</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">_new_stepsize</span><span class="p">,</span> <span class="n">stepsize_min</span><span class="p">,</span> <span class="n">stepsize_max</span><span class="p">)</span>

</pre></div>
</div>
<p>The final updates list is then returned.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="k">return</span> <span class="p">[(</span><span class="n">positions</span><span class="p">,</span> <span class="n">new_positions</span><span class="p">),</span>
            <span class="p">(</span><span class="n">stepsize</span><span class="p">,</span> <span class="n">new_stepsize</span><span class="p">),</span>
            <span class="p">(</span><span class="n">avg_acceptance_rate</span><span class="p">,</span> <span class="n">new_acceptance_rate</span><span class="p">)]</span>
</pre></div>
</div>
<p><strong>HMC_sampler</strong></p>
<p>We finally tie everything together using the <span class="math">HMC\_Sampler</span> class. Its main
elements are:</p>
<ul class="simple">
<li><p><span class="math">new\_from\_shared\_positions</span>: a constructor method which allocates various
shared variables and strings together the calls to <span class="math">hmc\_move</span> and
<span class="math">hmc\_updates</span>. It also builds the theano function <span class="math">simulate</span>, whose sole
purpose is to execute the updates generated by <span class="math">hmc\_updates</span>.</p></li>
<li><p><span class="math">draw</span>: a convenience method which calls the Theano function <span class="math">simulate</span>
and returns a copy of the contents of the shared variable <span class="math">self.positions</span>.</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">HMC_sampler</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convenience wrapper for performing Hybrid Monte Carlo (HMC). It creates the</span>
<span class="sd">    symbolic graph for performing an HMC simulation (using `hmc_move` and</span>
<span class="sd">    `hmc_updates`). The graph is then compiled into the `simulate` function, a</span>
<span class="sd">    theano function which runs the simulation and updates the required shared</span>
<span class="sd">    variables.</span>

<span class="sd">    Users should interface with the sampler thorugh the `draw` function which</span>
<span class="sd">    advances the markov chain and returns the current sample by calling</span>
<span class="sd">    `simulate` and `get_position` in sequence.</span>

<span class="sd">    The hyper-parameters are the same as those used by Marc&#39;Aurelio&#39;s</span>
<span class="sd">    &#39;train_mcRBM.py&#39; file (available on his personal home page).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">new_from_shared_positions</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">shared_positions</span><span class="p">,</span>
        <span class="n">energy_fn</span><span class="p">,</span>
        <span class="n">initial_stepsize</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
        <span class="n">target_acceptance_rate</span><span class="o">=</span><span class="mf">.9</span><span class="p">,</span>
        <span class="n">n_steps</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
        <span class="n">stepsize_dec</span><span class="o">=</span><span class="mf">0.98</span><span class="p">,</span>
        <span class="n">stepsize_min</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
        <span class="n">stepsize_max</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
        <span class="n">stepsize_inc</span><span class="o">=</span><span class="mf">1.02</span><span class="p">,</span>
        <span class="c1"># used in geometric avg. 1.0 would be not moving at all</span>
        <span class="n">avg_acceptance_slowness</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
        <span class="n">seed</span><span class="o">=</span><span class="mi">12345</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :param shared_positions: theano ndarray shared var with</span>
<span class="sd">            many particle [initial] positions</span>

<span class="sd">        :param energy_fn:</span>
<span class="sd">            callable such that energy_fn(positions)</span>
<span class="sd">            returns theano vector of energies.</span>
<span class="sd">            The len of this vector is the batchsize.</span>

<span class="sd">            The sum of this energy vector must be differentiable (with</span>
<span class="sd">            theano.tensor.grad) with respect to the positions for HMC</span>
<span class="sd">            sampling to work.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># allocate shared variables</span>
        <span class="n">stepsize</span> <span class="o">=</span> <span class="n">sharedX</span><span class="p">(</span><span class="n">initial_stepsize</span><span class="p">,</span> <span class="s1">&#39;hmc_stepsize&#39;</span><span class="p">)</span>
        <span class="n">avg_acceptance_rate</span> <span class="o">=</span> <span class="n">sharedX</span><span class="p">(</span><span class="n">target_acceptance_rate</span><span class="p">,</span>
                                      <span class="s1">&#39;avg_acceptance_rate&#39;</span><span class="p">)</span>
        <span class="n">s_rng</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">sandbox</span><span class="o">.</span><span class="n">rng_mrg</span><span class="o">.</span><span class="n">MRG_RandomStreams</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

        <span class="c1"># define graph for an `n_steps` HMC simulation</span>
        <span class="n">accept</span><span class="p">,</span> <span class="n">final_pos</span> <span class="o">=</span> <span class="n">hmc_move</span><span class="p">(</span>
            <span class="n">s_rng</span><span class="p">,</span>
            <span class="n">shared_positions</span><span class="p">,</span>
            <span class="n">energy_fn</span><span class="p">,</span>
            <span class="n">stepsize</span><span class="p">,</span>
            <span class="n">n_steps</span><span class="p">)</span>

        <span class="c1"># define the dictionary of updates, to apply on every `simulate` call</span>
        <span class="n">simulate_updates</span> <span class="o">=</span> <span class="n">hmc_updates</span><span class="p">(</span>
            <span class="n">shared_positions</span><span class="p">,</span>
            <span class="n">stepsize</span><span class="p">,</span>
            <span class="n">avg_acceptance_rate</span><span class="p">,</span>
            <span class="n">final_pos</span><span class="o">=</span><span class="n">final_pos</span><span class="p">,</span>
            <span class="n">accept</span><span class="o">=</span><span class="n">accept</span><span class="p">,</span>
            <span class="n">stepsize_min</span><span class="o">=</span><span class="n">stepsize_min</span><span class="p">,</span>
            <span class="n">stepsize_max</span><span class="o">=</span><span class="n">stepsize_max</span><span class="p">,</span>
            <span class="n">stepsize_inc</span><span class="o">=</span><span class="n">stepsize_inc</span><span class="p">,</span>
            <span class="n">stepsize_dec</span><span class="o">=</span><span class="n">stepsize_dec</span><span class="p">,</span>
            <span class="n">target_acceptance_rate</span><span class="o">=</span><span class="n">target_acceptance_rate</span><span class="p">,</span>
            <span class="n">avg_acceptance_slowness</span><span class="o">=</span><span class="n">avg_acceptance_slowness</span><span class="p">)</span>

        <span class="c1"># compile theano function</span>
        <span class="n">simulate</span> <span class="o">=</span> <span class="n">function</span><span class="p">([],</span> <span class="p">[],</span> <span class="n">updates</span><span class="o">=</span><span class="n">simulate_updates</span><span class="p">)</span>

        <span class="c1"># create HMC_sampler object with the following attributes ...</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">positions</span><span class="o">=</span><span class="n">shared_positions</span><span class="p">,</span>
            <span class="n">stepsize</span><span class="o">=</span><span class="n">stepsize</span><span class="p">,</span>
            <span class="n">stepsize_min</span><span class="o">=</span><span class="n">stepsize_min</span><span class="p">,</span>
            <span class="n">stepsize_max</span><span class="o">=</span><span class="n">stepsize_max</span><span class="p">,</span>
            <span class="n">avg_acceptance_rate</span><span class="o">=</span><span class="n">avg_acceptance_rate</span><span class="p">,</span>
            <span class="n">target_acceptance_rate</span><span class="o">=</span><span class="n">target_acceptance_rate</span><span class="p">,</span>
            <span class="n">s_rng</span><span class="o">=</span><span class="n">s_rng</span><span class="p">,</span>
            <span class="n">_updates</span><span class="o">=</span><span class="n">simulate_updates</span><span class="p">,</span>
            <span class="n">simulate</span><span class="o">=</span><span class="n">simulate</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">draw</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a new position obtained after `n_steps` of HMC simulation.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        kwargs: dictionary</span>
<span class="sd">            The `kwargs` dictionary is passed to the shared variable</span>
<span class="sd">            (self.positions) `get_value()` function.  For example, to avoid</span>
<span class="sd">            copying the shared variable value, consider passing `borrow=True`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        rval: numpy matrix</span>
<span class="sd">            Numpy matrix whose of dimensions similar to `initial_position`.</span>
<span class="sd">       &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">simulate</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">positions</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="n">borrow</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="testing-our-sampler">
<h2>Testing our Sampler<a class="headerlink" href="#testing-our-sampler" title="Permalink to this heading">¶</a></h2>
<p>We test our implementation of HMC by sampling from a multi-variate Gaussian
distribution. We start by generating a random mean vector <span class="math">mu</span> and covariance
matrix <span class="math">cov</span>, which allows us to define the energy function of the
corresponding Gaussian distribution: <span class="math">gaussian\_energy</span>.
We then initialize the state of the sampler by allocating a <span class="math">position</span> shared
variable. It is passed to the constructor of <span class="math">HMC\_sampler</span> along with our
target energy function.</p>
<p>Following a burn-in period, we then generate a large number of samples and
compare the empirical mean and covariance matrix to their true values.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sampler_on_nd_gaussian</span><span class="p">(</span><span class="n">sampler_cls</span><span class="p">,</span> <span class="n">burnin</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">batchsize</span> <span class="o">=</span> <span class="mi">3</span>

    <span class="n">rng</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>

    <span class="c1"># Define a covariance and mu for a gaussian</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span> <span class="o">*</span> <span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">theano</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">floatX</span><span class="p">)</span>
    <span class="n">cov</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">dim</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">theano</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">floatX</span><span class="p">)</span>
    <span class="n">cov</span> <span class="o">=</span> <span class="p">(</span><span class="n">cov</span> <span class="o">+</span> <span class="n">cov</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.</span>
    <span class="n">cov</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">dim</span><span class="p">),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">dim</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="n">cov_inv</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">cov</span><span class="p">)</span>

    <span class="c1"># Define energy function for a multi-variate Gaussian</span>
    <span class="k">def</span> <span class="nf">gaussian_energy</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">theano</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">dot</span><span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="n">mu</span><span class="p">),</span> <span class="n">cov_inv</span><span class="p">)</span> <span class="o">*</span>
                      <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mu</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Declared shared random variable for positions</span>
    <span class="n">position</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batchsize</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">theano</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">floatX</span><span class="p">)</span>
    <span class="n">position</span> <span class="o">=</span> <span class="n">theano</span><span class="o">.</span><span class="n">shared</span><span class="p">(</span><span class="n">position</span><span class="p">)</span>

    <span class="c1"># Create HMC sampler</span>
    <span class="n">sampler</span> <span class="o">=</span> <span class="n">sampler_cls</span><span class="p">(</span><span class="n">position</span><span class="p">,</span> <span class="n">gaussian_energy</span><span class="p">,</span>
                          <span class="n">initial_stepsize</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">stepsize_max</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

    <span class="c1"># Start with a burn-in process</span>
    <span class="n">garbage</span> <span class="o">=</span> <span class="p">[</span><span class="n">sampler</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">burnin</span><span class="p">)]</span>  <span class="c1"># burn-in Draw</span>
    <span class="c1"># `n_samples`: result is a 3D tensor of dim [n_samples, batchsize,</span>
    <span class="c1"># dim]</span>
    <span class="n">_samples</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">sampler</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)])</span>
    <span class="c1"># Flatten to [n_samples * batchsize, dim]</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">_samples</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;****** TARGET VALUES ******&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;target mean:&#39;</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;target cov:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">cov</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;****** EMPIRICAL MEAN/COV USING HMC ******&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;empirical mean: &#39;</span><span class="p">,</span> <span class="n">samples</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;empirical_cov:</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">numpy</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;****** HMC INTERNALS ******&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;final stepsize&#39;</span><span class="p">,</span> <span class="n">sampler</span><span class="o">.</span><span class="n">stepsize</span><span class="o">.</span><span class="n">get_value</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;final acceptance_rate&#39;</span><span class="p">,</span> <span class="n">sampler</span><span class="o">.</span><span class="n">avg_acceptance_rate</span><span class="o">.</span><span class="n">get_value</span><span class="p">())</span>

    <span class="k">return</span> <span class="n">sampler</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">test_hmc</span><span class="p">():</span>
    <span class="n">sampler</span> <span class="o">=</span> <span class="n">sampler_on_nd_gaussian</span><span class="p">(</span><span class="n">HMC_sampler</span><span class="o">.</span><span class="n">new_from_shared_positions</span><span class="p">,</span>
                                     <span class="n">burnin</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">abs</span><span class="p">(</span><span class="n">sampler</span><span class="o">.</span><span class="n">avg_acceptance_rate</span><span class="o">.</span><span class="n">get_value</span><span class="p">()</span> <span class="o">-</span>
               <span class="n">sampler</span><span class="o">.</span><span class="n">target_acceptance_rate</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">.1</span>
    <span class="k">assert</span> <span class="n">sampler</span><span class="o">.</span><span class="n">stepsize</span><span class="o">.</span><span class="n">get_value</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">stepsize_min</span>
    <span class="k">assert</span> <span class="n">sampler</span><span class="o">.</span><span class="n">stepsize</span><span class="o">.</span><span class="n">get_value</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">sampler</span><span class="o">.</span><span class="n">stepsize_max</span>
</pre></div>
</div>
<p>The above code can be run using the command: “nosetests -s code/hmc/test_hmc.py”. The output is as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>desjagui@atchoum<span class="w"> </span>hmc<span class="o">]</span>$<span class="w"> </span>python<span class="w"> </span>test_hmc.py

******<span class="w"> </span>TARGET<span class="w"> </span>VALUES<span class="w"> </span>******
target<span class="w"> </span>mean:<span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="m">6</span>.96469186<span class="w">  </span><span class="m">2</span>.86139335<span class="w">  </span><span class="m">2</span>.26851454<span class="w">  </span><span class="m">5</span>.51314769<span class="w">  </span><span class="m">7</span>.1946897<span class="w"> </span><span class="o">]</span>
target<span class="w"> </span>cov:
<span class="o">[[</span><span class="w"> </span><span class="m">1</span>.<span class="w">          </span><span class="m">0</span>.66197111<span class="w">  </span><span class="m">0</span>.71141257<span class="w">  </span><span class="m">0</span>.55766643<span class="w">  </span><span class="m">0</span>.35753822<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="m">0</span>.66197111<span class="w">  </span><span class="m">1</span>.<span class="w">          </span><span class="m">0</span>.31053199<span class="w">  </span><span class="m">0</span>.45455485<span class="w">  </span><span class="m">0</span>.37991646<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="m">0</span>.71141257<span class="w">  </span><span class="m">0</span>.31053199<span class="w">  </span><span class="m">1</span>.<span class="w">          </span><span class="m">0</span>.62800335<span class="w">  </span><span class="m">0</span>.38004541<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="m">0</span>.55766643<span class="w">  </span><span class="m">0</span>.45455485<span class="w">  </span><span class="m">0</span>.62800335<span class="w">  </span><span class="m">1</span>.<span class="w">          </span><span class="m">0</span>.50807871<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="m">0</span>.35753822<span class="w">  </span><span class="m">0</span>.37991646<span class="w">  </span><span class="m">0</span>.38004541<span class="w">  </span><span class="m">0</span>.50807871<span class="w">  </span><span class="m">1</span>.<span class="w">        </span><span class="o">]]</span>

******<span class="w"> </span>EMPIRICAL<span class="w"> </span>MEAN/COV<span class="w"> </span>USING<span class="w"> </span>HMC<span class="w"> </span>******
empirical<span class="w"> </span>mean:<span class="w">  </span><span class="o">[</span><span class="w"> </span><span class="m">6</span>.94155164<span class="w">  </span><span class="m">2</span>.81526039<span class="w">  </span><span class="m">2</span>.26301715<span class="w">  </span><span class="m">5</span>.46536853<span class="w">  </span><span class="m">7</span>.19414496<span class="o">]</span>
empirical_cov:
<span class="o">[[</span><span class="w"> </span><span class="m">1</span>.05152997<span class="w">  </span><span class="m">0</span>.68393537<span class="w">  </span><span class="m">0</span>.76038645<span class="w">  </span><span class="m">0</span>.59930252<span class="w">  </span><span class="m">0</span>.37478746<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="m">0</span>.68393537<span class="w">  </span><span class="m">0</span>.97708159<span class="w">  </span><span class="m">0</span>.37351422<span class="w">  </span><span class="m">0</span>.48362404<span class="w">  </span><span class="m">0</span>.3839558<span class="w"> </span><span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="m">0</span>.76038645<span class="w">  </span><span class="m">0</span>.37351422<span class="w">  </span><span class="m">1</span>.03797111<span class="w">  </span><span class="m">0</span>.67342957<span class="w">  </span><span class="m">0</span>.41529132<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="m">0</span>.59930252<span class="w">  </span><span class="m">0</span>.48362404<span class="w">  </span><span class="m">0</span>.67342957<span class="w">  </span><span class="m">1</span>.02865056<span class="w">  </span><span class="m">0</span>.53613649<span class="o">]</span>
<span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="m">0</span>.37478746<span class="w">  </span><span class="m">0</span>.3839558<span class="w">   </span><span class="m">0</span>.41529132<span class="w">  </span><span class="m">0</span>.53613649<span class="w">  </span><span class="m">0</span>.98721449<span class="o">]]</span>

******<span class="w"> </span>HMC<span class="w"> </span>INTERNALS<span class="w"> </span>******
final<span class="w"> </span>stepsize<span class="w"> </span><span class="m">0</span>.460446628091
final<span class="w"> </span>acceptance_rate<span class="w"> </span><span class="m">0</span>.922502043428
</pre></div>
</div>
<p>As can be seen above, the samples generated by our HMC sampler yield an
empirical mean and covariance matrix, which are very close to the true
underlying parameters. The adaptive algorithm also seemed to work well as the
final acceptance rate is close to our target of <span class="math">0.9</span>.</p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this heading">¶</a></h2>
<div role="list" class="citation-list">
<div class="citation" id="alder59" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Alder59<span class="fn-bracket">]</span></span>
<p>Alder, B. J. and Wainwright, T. E. (1959) “Studies in molecular dynamics. 1. General method”, Journal of Chemical Physics, vol. 31, pp. 459-466.</p>
</div>
<div class="citation" id="andersen80" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Andersen80<span class="fn-bracket">]</span></span>
<p>Andersen, H.C. (1980) “Molecular dynamics simulations at constant pressure and/or temperature”, Journal of Chemical Physics, vol. 72, pp. 2384-2393.</p>
</div>
<div class="citation" id="duane87" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">Duane87</a><span class="fn-bracket">]</span></span>
<p>Duane, S., Kennedy, A. D., Pendleton, B. J., and Roweth, D. (1987) “Hybrid Monte Carlo”, Physics Letters, vol. 195, pp. 216-222.</p>
</div>
<div class="citation" id="neal93" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Neal93<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id2">1</a>,<a role="doc-backlink" href="#id3">2</a>)</span>
<p>Neal, R. M. (1993) “Probabilistic Inference Using Markov Chain Monte Carlo Methods”, Technical Report CRG-TR-93-1, Dept. of Computer Science, University of Toronto, 144 pages</p>
</div>
</div>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <div>
    <h3><a href="contents.html">Table of Contents</a></h3>
    <ul>
<li><a class="reference internal" href="#">Hybrid Monte-Carlo Sampling</a><ul>
<li><a class="reference internal" href="#theory">Theory</a></li>
<li><a class="reference internal" href="#implementing-hmc-using-theano">Implementing HMC Using Theano</a></li>
<li><a class="reference internal" href="#testing-our-sampler">Testing our Sampler</a></li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>

  </div>
  <div>
    <h4>Previous topic</h4>
    <p class="topless"><a href="DBN.html"
                          title="previous chapter">Deep Belief Networks</a></p>
  </div>
  <div>
    <h4>Next topic</h4>
    <p class="topless"><a href="rnnslu.html"
                          title="next chapter">Recurrent Neural Networks with Word Embeddings</a></p>
  </div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/hmc.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="rnnslu.html" title="Recurrent Neural Networks with Word Embeddings"
             >next</a> |</li>
        <li class="right" >
          <a href="DBN.html" title="Deep Belief Networks"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="contents.html">DeepLearning 0.1 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Hybrid Monte-Carlo Sampling</a></li> 
      </ul>
    </div>

    <div class="footer" role="contentinfo">
        &#169; Copyright 2008--2010, LISA lab.
      Last updated on Mar 20, 2023.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 6.1.3.
    </div>
<script type="text/javascript">
  (function() {
    var ga = document.createElement('script');
    ga.src = ('https:' == document.location.protocol ?
              'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    ga.setAttribute('async', 'true');
    document.documentElement.firstChild.appendChild(ga);
  })();
</script>

  </body>
</html>